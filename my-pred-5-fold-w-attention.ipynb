{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa3c7b0",
   "metadata": {
    "papermill": {
     "duration": 0.004663,
     "end_time": "2024-09-25T18:20:17.185367",
     "exception": false,
     "start_time": "2024-09-25T18:20:17.180704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## This is a customized prediction method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe3234c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T18:20:17.195245Z",
     "iopub.status.busy": "2024-09-25T18:20:17.194832Z",
     "iopub.status.idle": "2024-09-25T18:22:03.437367Z",
     "shell.execute_reply": "2024-09-25T18:22:03.435945Z"
    },
    "papermill": {
     "duration": 106.250499,
     "end_time": "2024-09-25T18:22:03.440004",
     "exception": false,
     "start_time": "2024-09-25T18:20:17.189505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pydicom/data/data_manager.py:375: UserWarning: A download failure occurred while attempting to retrieve US1_J2KR.dcm\n",
      "  warn_and_log(\n",
      "/opt/conda/lib/python3.10/site-packages/pydicom/data/data_manager.py:375: UserWarning: A download failure occurred while attempting to retrieve MR-SIEMENS-DICOM-WithOverlays.dcm\n",
      "  warn_and_log(\n",
      "/opt/conda/lib/python3.10/site-packages/pydicom/data/data_manager.py:375: UserWarning: A download failure occurred while attempting to retrieve OBXXXX1A.dcm\n",
      "  warn_and_log(\n",
      "/opt/conda/lib/python3.10/site-packages/pydicom/data/data_manager.py:375: UserWarning: A download failure occurred while attempting to retrieve US1_UNCR.dcm\n",
      "  warn_and_log(\n",
      "/opt/conda/lib/python3.10/site-packages/pydicom/data/data_manager.py:375: UserWarning: A download failure occurred while attempting to retrieve color3d_jpeg_baseline.dcm\n",
      "  warn_and_log(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pydicom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "827d884a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T18:22:03.451601Z",
     "iopub.status.busy": "2024-09-25T18:22:03.450945Z",
     "iopub.status.idle": "2024-09-25T18:22:03.457102Z",
     "shell.execute_reply": "2024-09-25T18:22:03.456054Z"
    },
    "papermill": {
     "duration": 0.014448,
     "end_time": "2024-09-25T18:22:03.459317",
     "exception": false,
     "start_time": "2024-09-25T18:22:03.444869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define constants\n",
    "SERIES_DESCRIPTIONS = ['Sagittal T1', 'Sagittal T2_STIR', 'Axial T2']\n",
    "IMG_SIZE = (512, 512)\n",
    "TARGET_SLICES = 10\n",
    "rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d9b0eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T18:22:03.470346Z",
     "iopub.status.busy": "2024-09-25T18:22:03.469678Z",
     "iopub.status.idle": "2024-09-25T18:22:03.479101Z",
     "shell.execute_reply": "2024-09-25T18:22:03.478241Z"
    },
    "papermill": {
     "duration": 0.017689,
     "end_time": "2024-09-25T18:22:03.481441",
     "exception": false,
     "start_time": "2024-09-25T18:22:03.463752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions for natural sorting\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    \"\"\"\n",
    "    Alphanumeric sorting helper function.\n",
    "    \"\"\"\n",
    "    return [atoi(c) for c in re.split(r'(\\d+)', text)]\n",
    "\n",
    "# Function to resample slices\n",
    "def resample_slices(image_tensor, target_slices=10):\n",
    "    current_slices = image_tensor.shape[0]\n",
    "    if current_slices == target_slices:\n",
    "        return image_tensor  # No need to resample\n",
    "    if current_slices > target_slices:\n",
    "        indices = torch.linspace(0, current_slices - 1, target_slices).long()\n",
    "        return image_tensor[indices]\n",
    "    # If fewer slices, upsample\n",
    "    image_tensor = image_tensor.unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, num_slices, H, W]\n",
    "    image_tensor_resized = F.interpolate(\n",
    "        image_tensor,\n",
    "        size=(target_slices, image_tensor.shape[3], image_tensor.shape[4]),\n",
    "        mode='trilinear',\n",
    "        align_corners=False\n",
    "    )\n",
    "    image_tensor_resized = image_tensor_resized.squeeze(0).squeeze(0)  # Shape: [target_slices, H, W]\n",
    "    return image_tensor_resized\n",
    "\n",
    "# Define preprocessing transformations consistent with training\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1730588d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T18:22:03.492515Z",
     "iopub.status.busy": "2024-09-25T18:22:03.492117Z",
     "iopub.status.idle": "2024-09-25T18:22:03.511575Z",
     "shell.execute_reply": "2024-09-25T18:22:03.510356Z"
    },
    "papermill": {
     "duration": 0.027584,
     "end_time": "2024-09-25T18:22:03.513792",
     "exception": false,
     "start_time": "2024-09-25T18:22:03.486208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the test dataset class\n",
    "class LumbarSpineTestDataset(Dataset):\n",
    "    def __init__(self, df, study_ids, transform=None):\n",
    "        self.df = df\n",
    "        self.study_ids = study_ids\n",
    "        self.transform = transform\n",
    "\n",
    "    def get_img_paths(self, study_id, series_description):\n",
    "        pdf = self.df[self.df['study_id'] == study_id]\n",
    "        pdf_series = pdf[pdf['series_description'] == series_description]\n",
    "        image_paths = []\n",
    "        for idx, row in pdf_series.iterrows():\n",
    "            series_id = row['series_id']\n",
    "            paths = glob.glob(f'{rd}/test_images/{study_id}/{series_id}/*.dcm')\n",
    "            paths = sorted(paths, key=natural_keys)\n",
    "            image_paths.extend(paths)\n",
    "        return image_paths\n",
    "\n",
    "    def read_dcm_image(self, path):\n",
    "        dicom_data = pydicom.dcmread(path)\n",
    "        image = dicom_data.pixel_array.astype(np.float32)\n",
    "        # Normalize the image to [0, 255]\n",
    "        image = (image - image.min()) / (image.max() - image.min() + 1e-6) * 255.0\n",
    "        # Resize image to 512x512 using the same interpolation as training\n",
    "        image = cv2.resize(image, (512, 512), interpolation=cv2.INTER_CUBIC)\n",
    "        # Convert to PIL Image in grayscale\n",
    "        image = Image.fromarray(image.astype(np.uint8)).convert('L')\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.study_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        study_id = self.study_ids[idx]\n",
    "        images = {}\n",
    "        for series_description in SERIES_DESCRIPTIONS:\n",
    "            image_paths = self.get_img_paths(study_id, series_description)\n",
    "            if not image_paths:\n",
    "                images[series_description] = torch.zeros((10, IMG_SIZE[0], IMG_SIZE[1]))\n",
    "                continue\n",
    "\n",
    "            if series_description == 'Axial T2':\n",
    "                series_images = []\n",
    "                for img_path in image_paths:\n",
    "                    try:\n",
    "                        img = self.read_dcm_image(img_path)\n",
    "                        if self.transform:\n",
    "                            img = self.transform(img)\n",
    "                            img = img.squeeze(0)  # Remove channel dimension\n",
    "                        series_images.append(img)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {img_path}: {e}\")\n",
    "                if series_images:\n",
    "                    series_tensor = torch.stack(series_images, dim=0)  # [num_slices, H, W]\n",
    "                else:\n",
    "                    series_tensor = torch.zeros((1, IMG_SIZE[0], IMG_SIZE[1]))\n",
    "                # Resample to TARGET_SLICES (10 slices)\n",
    "                series_tensor = resample_slices(series_tensor, target_slices=10)\n",
    "                images[series_description] = series_tensor\n",
    "\n",
    "            elif series_description in ['Sagittal T1', 'Sagittal T2_STIR']:\n",
    "                series_images = []\n",
    "                allimgs = image_paths\n",
    "                len_imgs = len(allimgs)\n",
    "                if len_imgs == 0:\n",
    "                    images[series_description] = torch.zeros((10, IMG_SIZE[0], IMG_SIZE[1]))\n",
    "                    continue\n",
    "                step = len_imgs / 10.0\n",
    "                st = len_imgs / 2.0 - 4.0 * step\n",
    "                end = len_imgs + 0.0001\n",
    "                indices = []\n",
    "                for i in np.arange(st, end, step):\n",
    "                    ind2 = max(0, int((i - 0.5001).round()))\n",
    "                    indices.append(ind2)\n",
    "                selected_imgs = []\n",
    "                for ind in indices:\n",
    "                    if ind >= len_imgs:\n",
    "                        ind = len_imgs - 1\n",
    "                    img_path = allimgs[ind]\n",
    "                    try:\n",
    "                        img = self.read_dcm_image(img_path)\n",
    "                        if self.transform:\n",
    "                            img = self.transform(img)\n",
    "                            img = img.squeeze(0)  # Remove channel dimension\n",
    "                        selected_imgs.append(img)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {img_path}: {e}\")\n",
    "                if selected_imgs:\n",
    "                    series_tensor = torch.stack(selected_imgs, dim=0)  # [10, H, W]\n",
    "                else:\n",
    "                    series_tensor = torch.zeros((10, IMG_SIZE[0], IMG_SIZE[1]))\n",
    "                images[series_description] = series_tensor\n",
    "            else:\n",
    "                images[series_description] = torch.zeros((10, IMG_SIZE[0], IMG_SIZE[1]))\n",
    "        sample = {\n",
    "            'study_id': study_id,\n",
    "            'images': images\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e97ffd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T18:22:03.524425Z",
     "iopub.status.busy": "2024-09-25T18:22:03.524028Z",
     "iopub.status.idle": "2024-09-25T18:22:03.548955Z",
     "shell.execute_reply": "2024-09-25T18:22:03.547970Z"
    },
    "papermill": {
     "duration": 0.033359,
     "end_time": "2024-09-25T18:22:03.551571",
     "exception": false,
     "start_time": "2024-09-25T18:22:03.518212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read test_series_descriptions.csv\n",
    "test_df = pd.read_csv(f'{rd}/test_series_descriptions.csv')\n",
    "\n",
    "# Replace 'T2/STIR' with 'T2_STIR' in series descriptions\n",
    "test_df['series_description'] = test_df['series_description'].str.replace('T2/STIR', 'T2_STIR')\n",
    "\n",
    "study_ids = test_df['study_id'].unique()\n",
    "\n",
    "# Create the test dataset and dataloader\n",
    "test_dataset = LumbarSpineTestDataset(df=test_df, study_ids=study_ids, transform=transform)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,  # Adjust based on your system\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee160481",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T18:22:03.562224Z",
     "iopub.status.busy": "2024-09-25T18:22:03.561835Z",
     "iopub.status.idle": "2024-09-25T18:22:03.569860Z",
     "shell.execute_reply": "2024-09-25T18:22:03.568610Z"
    },
    "papermill": {
     "duration": 0.016186,
     "end_time": "2024-09-25T18:22:03.572336",
     "exception": false,
     "start_time": "2024-09-25T18:22:03.556150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the improved MultiSeriesSpineModel with proper weight initialization\n",
    "class SqueezeExcitationBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SqueezeExcitationBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(batch_size, channels)\n",
    "        y = self.fc(y).view(batch_size, channels, 1, 1)\n",
    "        return x * y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c17b575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T18:22:03.583463Z",
     "iopub.status.busy": "2024-09-25T18:22:03.582879Z",
     "iopub.status.idle": "2024-09-25T18:22:03.598974Z",
     "shell.execute_reply": "2024-09-25T18:22:03.597863Z"
    },
    "papermill": {
     "duration": 0.024447,
     "end_time": "2024-09-25T18:22:03.601362",
     "exception": false,
     "start_time": "2024-09-25T18:22:03.576915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNetFeatureExtractor(nn.Module):\n",
    "    def __init__(self, in_channels=10, resnet_weights_path=None):\n",
    "        super(ResNetFeatureExtractor, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=False)\n",
    "        if resnet_weights_path:\n",
    "            resnet.load_state_dict(torch.load(resnet_weights_path))\n",
    "        # Modify the first convolutional layer to accept in_channels\n",
    "        resnet.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # Extract layers up to layer4 (exclude avgpool and fc layers)\n",
    "        self.features = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu,\n",
    "            resnet.maxpool,\n",
    "            resnet.layer1,\n",
    "            resnet.layer2,\n",
    "            resnet.layer3,\n",
    "            resnet.layer4\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "# Define the main model\n",
    "class MultiSeriesSpineModel(nn.Module):\n",
    "    def __init__(self, num_conditions=25, num_classes=3):\n",
    "        super(MultiSeriesSpineModel, self).__init__()\n",
    "        self.num_conditions = num_conditions\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Feature extractors for each MRI series\n",
    "        self.cnn_sagittal_t1 = ResNetFeatureExtractor(in_channels=10)\n",
    "        self.cnn_sagittal_t2_stir = ResNetFeatureExtractor(in_channels=10)\n",
    "        self.cnn_axial_t2 = ResNetFeatureExtractor(in_channels=10)\n",
    "\n",
    "        # Define attention layers for each series\n",
    "        self.attention_sagittal_t1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.attention_sagittal_t2_stir = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.attention_axial_t2 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Define the final classification layers\n",
    "        combined_feature_size = 512 * 3  # Since we're concatenating features from three models\n",
    "\n",
    "        self.fc1 = nn.Linear(combined_feature_size, 512)\n",
    "        self.fc2 = nn.Linear(512, num_conditions * num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, sagittal_t1, sagittal_t2_stir, axial_t2):\n",
    "        # The tensors are of shape [batch_size, in_channels, H, W]\n",
    "\n",
    "        features_sagittal_t1 = self.cnn_sagittal_t1(sagittal_t1)  # Shape: [batch_size, 512, H, W]\n",
    "        features_sagittal_t2_stir = self.cnn_sagittal_t2_stir(sagittal_t2_stir)\n",
    "        features_axial_t2 = self.cnn_axial_t2(axial_t2)\n",
    "\n",
    "        # Generate attention maps (learned by the model)\n",
    "        attention_map_t1 = self.attention_sagittal_t1(features_sagittal_t1)  # Shape: [batch_size, 1, H, W]\n",
    "        attention_map_t2_stir = self.attention_sagittal_t2_stir(features_sagittal_t2_stir)\n",
    "        attention_map_axial = self.attention_axial_t2(features_axial_t2)\n",
    "\n",
    "        # Apply attention\n",
    "        attended_features_t1 = features_sagittal_t1 * attention_map_t1  # Element-wise multiplication\n",
    "        attended_features_t2_stir = features_sagittal_t2_stir * attention_map_t2_stir\n",
    "        attended_features_axial = features_axial_t2 * attention_map_axial\n",
    "\n",
    "        # Global average pooling\n",
    "        features_sagittal_t1 = F.adaptive_avg_pool2d(attended_features_t1, (1, 1)).view(attended_features_t1.size(0), -1)\n",
    "        features_sagittal_t2_stir = F.adaptive_avg_pool2d(attended_features_t2_stir, (1, 1)).view(attended_features_t2_stir.size(0), -1)\n",
    "        features_axial_t2 = F.adaptive_avg_pool2d(attended_features_axial, (1, 1)).view(attended_features_axial.size(0), -1)\n",
    "\n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat([features_sagittal_t1, features_sagittal_t2_stir, features_axial_t2], dim=1)\n",
    "\n",
    "        # Pass through final classification layers\n",
    "        x = F.relu(self.fc1(combined_features))\n",
    "        x = self.fc2(x)  # Shape: [batch_size, num_conditions * num_classes]\n",
    "        x = x.view(-1, self.num_conditions, self.num_classes)  # Reshape to [batch_size, num_conditions, num_classes]\n",
    "\n",
    "        return x, [attention_map_t1, attention_map_t2_stir, attention_map_axial]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ed15df9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T18:22:03.612247Z",
     "iopub.status.busy": "2024-09-25T18:22:03.611360Z",
     "iopub.status.idle": "2024-09-25T18:22:05.573754Z",
     "shell.execute_reply": "2024-09-25T18:22:05.572601Z"
    },
    "papermill": {
     "duration": 1.970568,
     "end_time": "2024-09-25T18:22:05.576349",
     "exception": false,
     "start_time": "2024-09-25T18:22:03.605781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_17/954994236.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "num_conditions = 25  # Number of labels\n",
    "num_classes = 3\n",
    "\n",
    "resnet_weights_path = '/kaggle/input/rsna-chacha-pytorch-models/pytorch/default/13/resnet18-f37072fd.pth'# Get pretrained weights from local\n",
    "\n",
    "\n",
    "model = MultiSeriesSpineModel(num_conditions=num_conditions, num_classes=num_classes)\n",
    "\n",
    "# Load the trained model's state_dict\n",
    "# Update this path to where your model weights are saved\n",
    "model_save_path = '/kaggle/input/rsna-chacha-pytorch-models/pytorch/default/13/model_fold_2.pth'\n",
    "model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "\n",
    "# Move the model to device\n",
    "model = model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define your label names consistent with training\n",
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis', \n",
    "    'left_neural_foraminal_narrowing', \n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n",
    "\n",
    "LEVELS = [\n",
    "    'l1_l2',\n",
    "    'l2_l3',\n",
    "    'l3_l4',\n",
    "    'l4_l5',\n",
    "    'l5_s1',\n",
    "]\n",
    "\n",
    "LABELS = [f'{condition}_{level}' for condition in CONDITIONS for level in LEVELS]\n",
    "\n",
    "# Initialize lists for row names and predictions\n",
    "row_names = []\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e0ff657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T18:22:05.587647Z",
     "iopub.status.busy": "2024-09-25T18:22:05.587181Z",
     "iopub.status.idle": "2024-09-25T18:22:07.978561Z",
     "shell.execute_reply": "2024-09-25T18:22:07.977209Z"
    },
    "papermill": {
     "duration": 2.399715,
     "end_time": "2024-09-25T18:22:07.980792",
     "exception": false,
     "start_time": "2024-09-25T18:22:05.581077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# Perform predictions\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        study_id = batch['study_id'][0]\n",
    "        images = batch['images']\n",
    "\n",
    "        # Process sagittal_t1\n",
    "        sagittal_t1 = images['Sagittal T1']  # Shape: [10, H, W]\n",
    "        sagittal_t1 = sagittal_t1.unsqueeze(0)  # Add batch dimension: [1, num_slices, H, W]\n",
    "        sagittal_t1 = sagittal_t1.reshape(1, -1, 512, 512).to(device)  # Shape: [1, num_channels, H, W]\n",
    "\n",
    "        # Process sagittal_t2_stir\n",
    "        sagittal_t2_stir = images['Sagittal T2_STIR']\n",
    "        sagittal_t2_stir = sagittal_t2_stir.unsqueeze(0).reshape(1, -1, 512, 512).to(device)\n",
    "\n",
    "        # Process axial_t2\n",
    "        axial_t2 = images['Axial T2']\n",
    "        axial_t2 = axial_t2.unsqueeze(0).reshape(1, -1, 512, 512).to(device)\n",
    "\n",
    "        # Now pass these tensors to the model\n",
    "        outputs, _ = model(sagittal_t1, sagittal_t2_stir, axial_t2)\n",
    "\n",
    "        # outputs shape: [1, num_conditions, num_classes]\n",
    "        outputs = outputs.squeeze(0)  # Shape: [num_conditions, num_classes]\n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probs = F.softmax(outputs, dim=1)  # Shape: [num_conditions, num_classes]\n",
    "\n",
    "        # Ensure the predictions are aligned with LABELS\n",
    "        pred_per_study = probs.cpu().numpy()  # Shape: [num_conditions, num_classes]\n",
    "\n",
    "        # Generate row names and collect predictions\n",
    "        for label in LABELS:\n",
    "            row_names.append(f'{study_id}_{label}')\n",
    "        predictions.append(pred_per_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec5ee5da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T18:22:07.992704Z",
     "iopub.status.busy": "2024-09-25T18:22:07.992271Z",
     "iopub.status.idle": "2024-09-25T18:22:08.005491Z",
     "shell.execute_reply": "2024-09-25T18:22:08.004025Z"
    },
    "papermill": {
     "duration": 0.022091,
     "end_time": "2024-09-25T18:22:08.007918",
     "exception": false,
     "start_time": "2024-09-25T18:22:07.985827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'submission.csv' has been generated.\n"
     ]
    }
   ],
   "source": [
    "# Stack predictions\n",
    "predictions = np.vstack(predictions)  # Shape: [num_studies * num_conditions, num_classes]\n",
    "\n",
    "# Flatten predictions\n",
    "predictions = predictions.reshape(-1, 3)  # Shape: [num_studies * num_conditions, num_classes]\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'row_id': row_names,\n",
    "    'normal_mild': predictions[:, 0],\n",
    "    'moderate': predictions[:, 1],\n",
    "    'severe': predictions[:, 2]\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file 'submission.csv' has been generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c18e5c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T18:22:08.020716Z",
     "iopub.status.busy": "2024-09-25T18:22:08.020288Z",
     "iopub.status.idle": "2024-09-25T18:22:08.040400Z",
     "shell.execute_reply": "2024-09-25T18:22:08.039129Z"
    },
    "papermill": {
     "duration": 0.02874,
     "end_time": "2024-09-25T18:22:08.042785",
     "exception": false,
     "start_time": "2024-09-25T18:22:08.014045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>normal_mild</th>\n",
       "      <th>moderate</th>\n",
       "      <th>severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l1_l2</td>\n",
       "      <td>0.980891</td>\n",
       "      <td>0.016559</td>\n",
       "      <td>0.002550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l2_l3</td>\n",
       "      <td>0.960810</td>\n",
       "      <td>0.032869</td>\n",
       "      <td>0.006322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l3_l4</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.074984</td>\n",
       "      <td>0.014760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l4_l5</td>\n",
       "      <td>0.804330</td>\n",
       "      <td>0.142722</td>\n",
       "      <td>0.052949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l5_s1</td>\n",
       "      <td>0.958560</td>\n",
       "      <td>0.032040</td>\n",
       "      <td>0.009399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>0.989171</td>\n",
       "      <td>0.010687</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>0.936755</td>\n",
       "      <td>0.062290</td>\n",
       "      <td>0.000955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>0.766925</td>\n",
       "      <td>0.220987</td>\n",
       "      <td>0.012087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>0.590597</td>\n",
       "      <td>0.351070</td>\n",
       "      <td>0.058333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>0.611733</td>\n",
       "      <td>0.280568</td>\n",
       "      <td>0.107699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>0.976777</td>\n",
       "      <td>0.021531</td>\n",
       "      <td>0.001692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>0.932620</td>\n",
       "      <td>0.066726</td>\n",
       "      <td>0.000654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>0.794439</td>\n",
       "      <td>0.194170</td>\n",
       "      <td>0.011390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>0.565964</td>\n",
       "      <td>0.376523</td>\n",
       "      <td>0.057513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>0.631158</td>\n",
       "      <td>0.269901</td>\n",
       "      <td>0.098941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l1_l2</td>\n",
       "      <td>0.967054</td>\n",
       "      <td>0.027031</td>\n",
       "      <td>0.005915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l2_l3</td>\n",
       "      <td>0.885195</td>\n",
       "      <td>0.098305</td>\n",
       "      <td>0.016501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l3_l4</td>\n",
       "      <td>0.719971</td>\n",
       "      <td>0.240985</td>\n",
       "      <td>0.039044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l4_l5</td>\n",
       "      <td>0.352355</td>\n",
       "      <td>0.472506</td>\n",
       "      <td>0.175138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l5_s1</td>\n",
       "      <td>0.650261</td>\n",
       "      <td>0.280153</td>\n",
       "      <td>0.069586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l1_l2</td>\n",
       "      <td>0.960514</td>\n",
       "      <td>0.034873</td>\n",
       "      <td>0.004613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l2_l3</td>\n",
       "      <td>0.890314</td>\n",
       "      <td>0.096251</td>\n",
       "      <td>0.013436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l3_l4</td>\n",
       "      <td>0.701087</td>\n",
       "      <td>0.262314</td>\n",
       "      <td>0.036600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l4_l5</td>\n",
       "      <td>0.330310</td>\n",
       "      <td>0.501453</td>\n",
       "      <td>0.168237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l5_s1</td>\n",
       "      <td>0.629936</td>\n",
       "      <td>0.274579</td>\n",
       "      <td>0.095484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             row_id  normal_mild  moderate  \\\n",
       "0              44036939_spinal_canal_stenosis_l1_l2     0.980891  0.016559   \n",
       "1              44036939_spinal_canal_stenosis_l2_l3     0.960810  0.032869   \n",
       "2              44036939_spinal_canal_stenosis_l3_l4     0.910256  0.074984   \n",
       "3              44036939_spinal_canal_stenosis_l4_l5     0.804330  0.142722   \n",
       "4              44036939_spinal_canal_stenosis_l5_s1     0.958560  0.032040   \n",
       "5    44036939_left_neural_foraminal_narrowing_l1_l2     0.989171  0.010687   \n",
       "6    44036939_left_neural_foraminal_narrowing_l2_l3     0.936755  0.062290   \n",
       "7    44036939_left_neural_foraminal_narrowing_l3_l4     0.766925  0.220987   \n",
       "8    44036939_left_neural_foraminal_narrowing_l4_l5     0.590597  0.351070   \n",
       "9    44036939_left_neural_foraminal_narrowing_l5_s1     0.611733  0.280568   \n",
       "10  44036939_right_neural_foraminal_narrowing_l1_l2     0.976777  0.021531   \n",
       "11  44036939_right_neural_foraminal_narrowing_l2_l3     0.932620  0.066726   \n",
       "12  44036939_right_neural_foraminal_narrowing_l3_l4     0.794439  0.194170   \n",
       "13  44036939_right_neural_foraminal_narrowing_l4_l5     0.565964  0.376523   \n",
       "14  44036939_right_neural_foraminal_narrowing_l5_s1     0.631158  0.269901   \n",
       "15        44036939_left_subarticular_stenosis_l1_l2     0.967054  0.027031   \n",
       "16        44036939_left_subarticular_stenosis_l2_l3     0.885195  0.098305   \n",
       "17        44036939_left_subarticular_stenosis_l3_l4     0.719971  0.240985   \n",
       "18        44036939_left_subarticular_stenosis_l4_l5     0.352355  0.472506   \n",
       "19        44036939_left_subarticular_stenosis_l5_s1     0.650261  0.280153   \n",
       "20       44036939_right_subarticular_stenosis_l1_l2     0.960514  0.034873   \n",
       "21       44036939_right_subarticular_stenosis_l2_l3     0.890314  0.096251   \n",
       "22       44036939_right_subarticular_stenosis_l3_l4     0.701087  0.262314   \n",
       "23       44036939_right_subarticular_stenosis_l4_l5     0.330310  0.501453   \n",
       "24       44036939_right_subarticular_stenosis_l5_s1     0.629936  0.274579   \n",
       "\n",
       "      severe  \n",
       "0   0.002550  \n",
       "1   0.006322  \n",
       "2   0.014760  \n",
       "3   0.052949  \n",
       "4   0.009399  \n",
       "5   0.000142  \n",
       "6   0.000955  \n",
       "7   0.012087  \n",
       "8   0.058333  \n",
       "9   0.107699  \n",
       "10  0.001692  \n",
       "11  0.000654  \n",
       "12  0.011390  \n",
       "13  0.057513  \n",
       "14  0.098941  \n",
       "15  0.005915  \n",
       "16  0.016501  \n",
       "17  0.039044  \n",
       "18  0.175138  \n",
       "19  0.069586  \n",
       "20  0.004613  \n",
       "21  0.013436  \n",
       "22  0.036600  \n",
       "23  0.168237  \n",
       "24  0.095484  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a751a",
   "metadata": {
    "papermill": {
     "duration": 0.004961,
     "end_time": "2024-09-25T18:22:08.053185",
     "exception": false,
     "start_time": "2024-09-25T18:22:08.048224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "modelId": 120206,
     "modelInstanceId": 96019,
     "sourceId": 120801,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 115.143946,
   "end_time": "2024-09-25T18:22:09.281705",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-25T18:20:14.137759",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
