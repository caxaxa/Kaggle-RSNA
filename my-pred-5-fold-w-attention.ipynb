{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc30cb7",
   "metadata": {
    "papermill": {
     "duration": 0.007531,
     "end_time": "2024-10-03T19:06:35.212074",
     "exception": false,
     "start_time": "2024-10-03T19:06:35.204543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## This is a customized prediction method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c095bb6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T19:06:35.227718Z",
     "iopub.status.busy": "2024-10-03T19:06:35.226459Z",
     "iopub.status.idle": "2024-10-03T19:08:22.533981Z",
     "shell.execute_reply": "2024-10-03T19:08:22.532552Z"
    },
    "papermill": {
     "duration": 107.317976,
     "end_time": "2024-10-03T19:08:22.536960",
     "exception": false,
     "start_time": "2024-10-03T19:06:35.218984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pydicom/data/data_manager.py:375: UserWarning: A download failure occurred while attempting to retrieve US1_J2KR.dcm\n",
      "  warn_and_log(\n",
      "/opt/conda/lib/python3.10/site-packages/pydicom/data/data_manager.py:375: UserWarning: A download failure occurred while attempting to retrieve MR-SIEMENS-DICOM-WithOverlays.dcm\n",
      "  warn_and_log(\n",
      "/opt/conda/lib/python3.10/site-packages/pydicom/data/data_manager.py:375: UserWarning: A download failure occurred while attempting to retrieve OBXXXX1A.dcm\n",
      "  warn_and_log(\n",
      "/opt/conda/lib/python3.10/site-packages/pydicom/data/data_manager.py:375: UserWarning: A download failure occurred while attempting to retrieve US1_UNCR.dcm\n",
      "  warn_and_log(\n",
      "/opt/conda/lib/python3.10/site-packages/pydicom/data/data_manager.py:375: UserWarning: A download failure occurred while attempting to retrieve color3d_jpeg_baseline.dcm\n",
      "  warn_and_log(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pydicom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9268dc80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T19:08:22.552245Z",
     "iopub.status.busy": "2024-10-03T19:08:22.551589Z",
     "iopub.status.idle": "2024-10-03T19:08:22.558505Z",
     "shell.execute_reply": "2024-10-03T19:08:22.557273Z"
    },
    "papermill": {
     "duration": 0.017491,
     "end_time": "2024-10-03T19:08:22.561131",
     "exception": false,
     "start_time": "2024-10-03T19:08:22.543640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define constants\n",
    "SERIES_DESCRIPTIONS = ['Sagittal T1', 'Sagittal T2_STIR', 'Axial T2']\n",
    "IMG_SIZE = (512, 512)\n",
    "TARGET_SLICES = 10\n",
    "rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "160b3289",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T19:08:22.576753Z",
     "iopub.status.busy": "2024-10-03T19:08:22.575949Z",
     "iopub.status.idle": "2024-10-03T19:08:22.587067Z",
     "shell.execute_reply": "2024-10-03T19:08:22.585939Z"
    },
    "papermill": {
     "duration": 0.021732,
     "end_time": "2024-10-03T19:08:22.589625",
     "exception": false,
     "start_time": "2024-10-03T19:08:22.567893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions for natural sorting\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    \"\"\"\n",
    "    Alphanumeric sorting helper function.\n",
    "    \"\"\"\n",
    "    return [atoi(c) for c in re.split(r'(\\d+)', text)]\n",
    "\n",
    "# Function to resample slices\n",
    "def resample_slices(image_tensor, target_slices=10):\n",
    "    current_slices = image_tensor.shape[0]\n",
    "    if current_slices == target_slices:\n",
    "        return image_tensor  # No need to resample\n",
    "    if current_slices > target_slices:\n",
    "        indices = torch.linspace(0, current_slices - 1, target_slices).long()\n",
    "        return image_tensor[indices]\n",
    "    # If fewer slices, upsample\n",
    "    image_tensor = image_tensor.unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, num_slices, H, W]\n",
    "    image_tensor_resized = F.interpolate(\n",
    "        image_tensor,\n",
    "        size=(target_slices, image_tensor.shape[3], image_tensor.shape[4]),\n",
    "        mode='trilinear',\n",
    "        align_corners=False\n",
    "    )\n",
    "    image_tensor_resized = image_tensor_resized.squeeze(0).squeeze(0)  # Shape: [target_slices, H, W]\n",
    "    return image_tensor_resized\n",
    "\n",
    "# Define preprocessing transformations consistent with training\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd51aa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T19:08:22.605473Z",
     "iopub.status.busy": "2024-10-03T19:08:22.605018Z",
     "iopub.status.idle": "2024-10-03T19:08:22.632408Z",
     "shell.execute_reply": "2024-10-03T19:08:22.631136Z"
    },
    "papermill": {
     "duration": 0.038939,
     "end_time": "2024-10-03T19:08:22.635284",
     "exception": false,
     "start_time": "2024-10-03T19:08:22.596345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the test dataset class\n",
    "class LumbarSpineTestDataset(Dataset):\n",
    "    def __init__(self, df, study_ids, transform=None):\n",
    "        self.df = df\n",
    "        self.study_ids = study_ids\n",
    "        self.transform = transform\n",
    "\n",
    "    def get_img_paths(self, study_id, series_description):\n",
    "        pdf = self.df[self.df['study_id'] == study_id]\n",
    "        pdf_series = pdf[pdf['series_description'] == series_description]\n",
    "        image_paths = []\n",
    "        for idx, row in pdf_series.iterrows():\n",
    "            series_id = row['series_id']\n",
    "            paths = glob.glob(f'{rd}/test_images/{study_id}/{series_id}/*.dcm')\n",
    "            paths = sorted(paths, key=natural_keys)\n",
    "            image_paths.extend(paths)\n",
    "        return image_paths\n",
    "\n",
    "    def read_dcm_image(self, path):\n",
    "        dicom_data = pydicom.dcmread(path)\n",
    "        image = dicom_data.pixel_array.astype(np.float32)\n",
    "        # Normalize the image to [0, 255]\n",
    "        image = (image - image.min()) / (image.max() - image.min() + 1e-6) * 255.0\n",
    "        # Resize image to 512x512 using the same interpolation as training\n",
    "        image = cv2.resize(image, (512, 512), interpolation=cv2.INTER_CUBIC)\n",
    "        # Convert to PIL Image in grayscale\n",
    "        image = Image.fromarray(image.astype(np.uint8)).convert('L')\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.study_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        study_id = self.study_ids[idx]\n",
    "        images = {}\n",
    "        for series_description in SERIES_DESCRIPTIONS:\n",
    "            image_paths = self.get_img_paths(study_id, series_description)\n",
    "            if not image_paths:\n",
    "                images[series_description] = torch.zeros((10, IMG_SIZE[0], IMG_SIZE[1]))\n",
    "                continue\n",
    "\n",
    "            if series_description == 'Axial T2':\n",
    "                series_images = []\n",
    "                for img_path in image_paths:\n",
    "                    try:\n",
    "                        img = self.read_dcm_image(img_path)\n",
    "                        if self.transform:\n",
    "                            img = self.transform(img)\n",
    "                            img = img.squeeze(0)  # Remove channel dimension\n",
    "                        series_images.append(img)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {img_path}: {e}\")\n",
    "                if series_images:\n",
    "                    series_tensor = torch.stack(series_images, dim=0)  # [num_slices, H, W]\n",
    "                else:\n",
    "                    series_tensor = torch.zeros((1, IMG_SIZE[0], IMG_SIZE[1]))\n",
    "                # Resample to TARGET_SLICES (10 slices)\n",
    "                series_tensor = resample_slices(series_tensor, target_slices=10)\n",
    "                images[series_description] = series_tensor\n",
    "\n",
    "            elif series_description in ['Sagittal T1', 'Sagittal T2_STIR']:\n",
    "                series_images = []\n",
    "                allimgs = image_paths\n",
    "                len_imgs = len(allimgs)\n",
    "                if len_imgs == 0:\n",
    "                    images[series_description] = torch.zeros((10, IMG_SIZE[0], IMG_SIZE[1]))\n",
    "                    continue\n",
    "                step = len_imgs / 10.0\n",
    "                st = len_imgs / 2.0 - 4.0 * step\n",
    "                end = len_imgs + 0.0001\n",
    "                indices = []\n",
    "                for i in np.arange(st, end, step):\n",
    "                    ind2 = max(0, int((i - 0.5001).round()))\n",
    "                    indices.append(ind2)\n",
    "                selected_imgs = []\n",
    "                for ind in indices:\n",
    "                    if ind >= len_imgs:\n",
    "                        ind = len_imgs - 1\n",
    "                    img_path = allimgs[ind]\n",
    "                    try:\n",
    "                        img = self.read_dcm_image(img_path)\n",
    "                        if self.transform:\n",
    "                            img = self.transform(img)\n",
    "                            img = img.squeeze(0)  # Remove channel dimension\n",
    "                        selected_imgs.append(img)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {img_path}: {e}\")\n",
    "                if selected_imgs:\n",
    "                    series_tensor = torch.stack(selected_imgs, dim=0)  # [10, H, W]\n",
    "                else:\n",
    "                    series_tensor = torch.zeros((10, IMG_SIZE[0], IMG_SIZE[1]))\n",
    "                images[series_description] = series_tensor\n",
    "            else:\n",
    "                images[series_description] = torch.zeros((10, IMG_SIZE[0], IMG_SIZE[1]))\n",
    "        sample = {\n",
    "            'study_id': study_id,\n",
    "            'images': images\n",
    "        }\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a43a5e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T19:08:22.652223Z",
     "iopub.status.busy": "2024-10-03T19:08:22.651706Z",
     "iopub.status.idle": "2024-10-03T19:08:22.680452Z",
     "shell.execute_reply": "2024-10-03T19:08:22.679213Z"
    },
    "papermill": {
     "duration": 0.040728,
     "end_time": "2024-10-03T19:08:22.683214",
     "exception": false,
     "start_time": "2024-10-03T19:08:22.642486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read test_series_descriptions.csv\n",
    "test_df = pd.read_csv(f'{rd}/test_series_descriptions.csv')\n",
    "\n",
    "# Replace 'T2/STIR' with 'T2_STIR' in series descriptions\n",
    "test_df['series_description'] = test_df['series_description'].str.replace('T2/STIR', 'T2_STIR')\n",
    "\n",
    "study_ids = test_df['study_id'].unique()\n",
    "\n",
    "# Create the test dataset and dataloader\n",
    "test_dataset = LumbarSpineTestDataset(df=test_df, study_ids=study_ids, transform=transform)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,  # Adjust based on your system\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7e05489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T19:08:22.698606Z",
     "iopub.status.busy": "2024-10-03T19:08:22.698117Z",
     "iopub.status.idle": "2024-10-03T19:08:22.719260Z",
     "shell.execute_reply": "2024-10-03T19:08:22.718048Z"
    },
    "papermill": {
     "duration": 0.032041,
     "end_time": "2024-10-03T19:08:22.722040",
     "exception": false,
     "start_time": "2024-10-03T19:08:22.689999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the ResNet feature extractor\n",
    "class ResNetFeatureExtractor(nn.Module):\n",
    "    def __init__(self, in_channels=10):\n",
    "        super(ResNetFeatureExtractor, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=False)\n",
    "        # Modify the first convolutional layer to accept in_channels\n",
    "        resnet.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # Extract layers up to layer4 (exclude avgpool and fc layers)\n",
    "        self.features = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu,\n",
    "            resnet.maxpool,\n",
    "            resnet.layer1,\n",
    "            resnet.layer2,\n",
    "            resnet.layer3,\n",
    "            resnet.layer4\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "# Define the main model\n",
    "class MultiSeriesSpineModel(nn.Module):\n",
    "    def __init__(self, num_conditions=25, num_classes=3):\n",
    "        super(MultiSeriesSpineModel, self).__init__()\n",
    "        self.num_conditions = num_conditions\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Feature extractors for each MRI series\n",
    "        self.cnn_sagittal_t1 = ResNetFeatureExtractor(in_channels=10)\n",
    "        self.cnn_sagittal_t2_stir = ResNetFeatureExtractor(in_channels=10)\n",
    "        self.cnn_axial_t2 = ResNetFeatureExtractor(in_channels=10)\n",
    "\n",
    "        # Define attention layers for each series\n",
    "        self.attention_sagittal_t1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.attention_sagittal_t2_stir = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.attention_axial_t2 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Define the final classification layers\n",
    "        combined_feature_size = 512 * 3  # Since we're concatenating features from three models\n",
    "\n",
    "        self.fc1 = nn.Linear(combined_feature_size, 512)\n",
    "        self.fc2 = nn.Linear(512, num_conditions * num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, sagittal_t1, sagittal_t2_stir, axial_t2):\n",
    "        # The tensors are of shape [batch_size, in_channels, H, W]\n",
    "        features_sagittal_t1 = self.cnn_sagittal_t1(sagittal_t1)  # Shape: [batch_size, 512, H, W]\n",
    "        features_sagittal_t2_stir = self.cnn_sagittal_t2_stir(sagittal_t2_stir)\n",
    "        features_axial_t2 = self.cnn_axial_t2(axial_t2)\n",
    "\n",
    "        # Generate attention maps (learned by the model)\n",
    "        attention_map_t1 = self.attention_sagittal_t1(features_sagittal_t1)  # Shape: [batch_size, 1, H, W]\n",
    "        attention_map_t2_stir = self.attention_sagittal_t2_stir(features_sagittal_t2_stir)\n",
    "        attention_map_axial = self.attention_axial_t2(features_axial_t2)\n",
    "\n",
    "        # Apply attention\n",
    "        attended_features_t1 = features_sagittal_t1 * attention_map_t1  # Element-wise multiplication\n",
    "        attended_features_t2_stir = features_sagittal_t2_stir * attention_map_t2_stir\n",
    "        attended_features_axial = features_axial_t2 * attention_map_axial\n",
    "\n",
    "        # Global average pooling\n",
    "        features_sagittal_t1 = F.adaptive_avg_pool2d(attended_features_t1, (1, 1)).view(attended_features_t1.size(0), -1)\n",
    "        features_sagittal_t2_stir = F.adaptive_avg_pool2d(attended_features_t2_stir, (1, 1)).view(attended_features_t2_stir.size(0), -1)\n",
    "        features_axial_t2 = F.adaptive_avg_pool2d(attended_features_axial, (1, 1)).view(attended_features_axial.size(0), -1)\n",
    "\n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat([features_sagittal_t1, features_sagittal_t2_stir, features_axial_t2], dim=1)\n",
    "\n",
    "        # Pass through final classification layers\n",
    "        x = F.relu(self.fc1(combined_features))\n",
    "        x = self.fc2(x)  # Shape: [batch_size, num_conditions * num_classes]\n",
    "        x = x.view(-1, self.num_conditions, self.num_classes)  # Reshape to [batch_size, num_conditions, num_classes]\n",
    "\n",
    "        return x, [attention_map_t1, attention_map_t2_stir, attention_map_axial]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b2b364",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T19:08:22.737403Z",
     "iopub.status.busy": "2024-10-03T19:08:22.736974Z",
     "iopub.status.idle": "2024-10-03T19:08:22.746199Z",
     "shell.execute_reply": "2024-10-03T19:08:22.744943Z"
    },
    "papermill": {
     "duration": 0.019769,
     "end_time": "2024-10-03T19:08:22.748524",
     "exception": false,
     "start_time": "2024-10-03T19:08:22.728755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the EnsembleModel class\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, model_class, num_models, device):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.models = nn.ModuleList()\n",
    "        for _ in range(num_models):\n",
    "            model = model_class()\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            self.models.append(model)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, sagittal_t1, sagittal_t2_stir, axial_t2):\n",
    "        outputs_list = []\n",
    "        for model in self.models:\n",
    "            outputs, _ = model(sagittal_t1, sagittal_t2_stir, axial_t2)\n",
    "            outputs_list.append(outputs)\n",
    "        # Stack outputs and take mean over the ensemble dimension\n",
    "        outputs = torch.stack(outputs_list, dim=0)\n",
    "        avg_outputs = torch.mean(outputs, dim=0)\n",
    "        return avg_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae15981b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T19:08:22.763777Z",
     "iopub.status.busy": "2024-10-03T19:08:22.763317Z",
     "iopub.status.idle": "2024-10-03T19:08:22.769068Z",
     "shell.execute_reply": "2024-10-03T19:08:22.767706Z"
    },
    "papermill": {
     "duration": 0.016385,
     "end_time": "2024-10-03T19:08:22.771752",
     "exception": false,
     "start_time": "2024-10-03T19:08:22.755367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the ensemble model\n",
    "num_conditions = 25  # Number of labels\n",
    "num_classes = 3\n",
    "k_folds = 3  # Number of models in the ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e802e8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T19:08:22.788726Z",
     "iopub.status.busy": "2024-10-03T19:08:22.787458Z",
     "iopub.status.idle": "2024-10-03T19:08:29.475202Z",
     "shell.execute_reply": "2024-10-03T19:08:29.473862Z"
    },
    "papermill": {
     "duration": 6.698999,
     "end_time": "2024-10-03T19:08:29.478449",
     "exception": false,
     "start_time": "2024-10-03T19:08:22.779450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_17/1140678201.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ensemble_model.load_state_dict(torch.load('/kaggle/input/rsna-chacha-pytorch-models/pytorch/default/20/ensemble_model_F3_E10.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EnsembleModel(\n",
       "  (models): ModuleList(\n",
       "    (0-2): 3 x MultiSeriesSpineModel(\n",
       "      (cnn_sagittal_t1): ResNetFeatureExtractor(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(10, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (4): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (6): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (7): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (cnn_sagittal_t2_stir): ResNetFeatureExtractor(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(10, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (4): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (6): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (7): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (cnn_axial_t2): ResNetFeatureExtractor(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(10, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (4): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (6): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (7): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (attention_sagittal_t1): Sequential(\n",
       "        (0): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sigmoid()\n",
       "      )\n",
       "      (attention_sagittal_t2_stir): Sequential(\n",
       "        (0): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sigmoid()\n",
       "      )\n",
       "      (attention_axial_t2): Sequential(\n",
       "        (0): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Sigmoid()\n",
       "      )\n",
       "      (fc1): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=75, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model = EnsembleModel(\n",
    "    model_class=lambda: MultiSeriesSpineModel(num_conditions=num_conditions, num_classes=num_classes),\n",
    "    num_models=k_folds,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "ensemble_model.load_state_dict(torch.load('/kaggle/input/rsna-chacha-pytorch-models/pytorch/default/20/ensemble_model_F3_E10.pth', map_location=device))\n",
    "ensemble_model.to(device)\n",
    "ensemble_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10f81e72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T19:08:29.495428Z",
     "iopub.status.busy": "2024-10-03T19:08:29.494998Z",
     "iopub.status.idle": "2024-10-03T19:08:29.502250Z",
     "shell.execute_reply": "2024-10-03T19:08:29.501000Z"
    },
    "papermill": {
     "duration": 0.018866,
     "end_time": "2024-10-03T19:08:29.504890",
     "exception": false,
     "start_time": "2024-10-03T19:08:29.486024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define your label names consistent with training\n",
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis', \n",
    "    'left_neural_foraminal_narrowing', \n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n",
    "\n",
    "LEVELS = [\n",
    "    'l1_l2',\n",
    "    'l2_l3',\n",
    "    'l3_l4',\n",
    "    'l4_l5',\n",
    "    'l5_s1',\n",
    "]\n",
    "\n",
    "LABELS = [f'{condition}_{level}' for condition in CONDITIONS for level in LEVELS]\n",
    "\n",
    "# Initialize lists for row names and predictions\n",
    "row_names = []\n",
    "predictions = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e20b2ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T19:08:29.522075Z",
     "iopub.status.busy": "2024-10-03T19:08:29.521588Z",
     "iopub.status.idle": "2024-10-03T19:08:33.861335Z",
     "shell.execute_reply": "2024-10-03T19:08:33.860094Z"
    },
    "papermill": {
     "duration": 4.351435,
     "end_time": "2024-10-03T19:08:33.863969",
     "exception": false,
     "start_time": "2024-10-03T19:08:29.512534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# Perform predictions\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        study_id = batch['study_id'][0]\n",
    "        images = batch['images']\n",
    "\n",
    "        # Process images\n",
    "        sagittal_t1 = images['Sagittal T1']  # Shape: [1, num_slices, H, W]\n",
    "        sagittal_t2_stir = images['Sagittal T2_STIR']\n",
    "        axial_t2 = images['Axial T2']\n",
    "\n",
    "        # Resample slices if necessary (already done in dataset)\n",
    "        # Stack slices into the channel dimension\n",
    "        sagittal_t1 = sagittal_t1.reshape(1, -1, 512, 512).to(device)  # Shape: [batch_size, channels, H, W]\n",
    "        sagittal_t2_stir = sagittal_t2_stir.reshape(1, -1, 512, 512).to(device)\n",
    "        axial_t2 = axial_t2.reshape(1, -1, 512, 512).to(device)\n",
    "\n",
    "        # Get ensemble prediction\n",
    "        outputs = ensemble_model(sagittal_t1, sagittal_t2_stir, axial_t2)\n",
    "\n",
    "        # outputs shape: [batch_size, num_conditions, num_classes]\n",
    "        outputs = outputs.squeeze(0)  # Shape: [num_conditions, num_classes]\n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probs = F.softmax(outputs, dim=1)  # Shape: [num_conditions, num_classes]\n",
    "\n",
    "        # Ensure the predictions are aligned with LABELS\n",
    "        pred_per_study = probs.cpu().numpy()  # Shape: [num_conditions, num_classes]\n",
    "\n",
    "        # Generate row names and collect predictions\n",
    "        for label in LABELS:\n",
    "            row_names.append(f'{study_id}_{label}')\n",
    "        predictions.append(pred_per_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f92370db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T19:08:33.882768Z",
     "iopub.status.busy": "2024-10-03T19:08:33.882310Z",
     "iopub.status.idle": "2024-10-03T19:08:33.895799Z",
     "shell.execute_reply": "2024-10-03T19:08:33.894264Z"
    },
    "papermill": {
     "duration": 0.025471,
     "end_time": "2024-10-03T19:08:33.898561",
     "exception": false,
     "start_time": "2024-10-03T19:08:33.873090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'submission.csv' has been generated.\n"
     ]
    }
   ],
   "source": [
    "# Stack predictions\n",
    "predictions = np.vstack(predictions)  # Shape: [num_studies * num_conditions, num_classes]\n",
    "\n",
    "# Flatten predictions\n",
    "predictions = predictions.reshape(-1, 3)  # Shape: [num_studies * num_conditions, num_classes]\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'row_id': row_names,\n",
    "    'normal_mild': predictions[:, 0],\n",
    "    'moderate': predictions[:, 1],\n",
    "    'severe': predictions[:, 2]\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file 'submission.csv' has been generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ddea81e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T19:08:33.916860Z",
     "iopub.status.busy": "2024-10-03T19:08:33.916351Z",
     "iopub.status.idle": "2024-10-03T19:08:33.938244Z",
     "shell.execute_reply": "2024-10-03T19:08:33.937067Z"
    },
    "papermill": {
     "duration": 0.034122,
     "end_time": "2024-10-03T19:08:33.940641",
     "exception": false,
     "start_time": "2024-10-03T19:08:33.906519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>normal_mild</th>\n",
       "      <th>moderate</th>\n",
       "      <th>severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l1_l2</td>\n",
       "      <td>0.326605</td>\n",
       "      <td>0.374253</td>\n",
       "      <td>0.299143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l2_l3</td>\n",
       "      <td>0.343004</td>\n",
       "      <td>0.325952</td>\n",
       "      <td>0.331044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l3_l4</td>\n",
       "      <td>0.364410</td>\n",
       "      <td>0.328353</td>\n",
       "      <td>0.307238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l4_l5</td>\n",
       "      <td>0.374329</td>\n",
       "      <td>0.285039</td>\n",
       "      <td>0.340632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l5_s1</td>\n",
       "      <td>0.323765</td>\n",
       "      <td>0.356296</td>\n",
       "      <td>0.319938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>0.338018</td>\n",
       "      <td>0.357842</td>\n",
       "      <td>0.304141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>0.355018</td>\n",
       "      <td>0.345650</td>\n",
       "      <td>0.299332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>0.336803</td>\n",
       "      <td>0.339710</td>\n",
       "      <td>0.323488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>0.369527</td>\n",
       "      <td>0.310421</td>\n",
       "      <td>0.320052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>0.324511</td>\n",
       "      <td>0.354080</td>\n",
       "      <td>0.321409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>0.349673</td>\n",
       "      <td>0.346692</td>\n",
       "      <td>0.303636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>0.305199</td>\n",
       "      <td>0.346349</td>\n",
       "      <td>0.348451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>0.334163</td>\n",
       "      <td>0.339846</td>\n",
       "      <td>0.325991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>0.353972</td>\n",
       "      <td>0.319242</td>\n",
       "      <td>0.326786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>0.348945</td>\n",
       "      <td>0.323386</td>\n",
       "      <td>0.327670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l1_l2</td>\n",
       "      <td>0.320001</td>\n",
       "      <td>0.334792</td>\n",
       "      <td>0.345207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l2_l3</td>\n",
       "      <td>0.364562</td>\n",
       "      <td>0.354611</td>\n",
       "      <td>0.280827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l3_l4</td>\n",
       "      <td>0.352349</td>\n",
       "      <td>0.346995</td>\n",
       "      <td>0.300656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l4_l5</td>\n",
       "      <td>0.335331</td>\n",
       "      <td>0.351148</td>\n",
       "      <td>0.313521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l5_s1</td>\n",
       "      <td>0.362480</td>\n",
       "      <td>0.318515</td>\n",
       "      <td>0.319005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l1_l2</td>\n",
       "      <td>0.398080</td>\n",
       "      <td>0.298709</td>\n",
       "      <td>0.303210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l2_l3</td>\n",
       "      <td>0.328432</td>\n",
       "      <td>0.345869</td>\n",
       "      <td>0.325699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l3_l4</td>\n",
       "      <td>0.354999</td>\n",
       "      <td>0.349790</td>\n",
       "      <td>0.295211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l4_l5</td>\n",
       "      <td>0.360246</td>\n",
       "      <td>0.313582</td>\n",
       "      <td>0.326172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l5_s1</td>\n",
       "      <td>0.344363</td>\n",
       "      <td>0.321940</td>\n",
       "      <td>0.333697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             row_id  normal_mild  moderate  \\\n",
       "0              44036939_spinal_canal_stenosis_l1_l2     0.326605  0.374253   \n",
       "1              44036939_spinal_canal_stenosis_l2_l3     0.343004  0.325952   \n",
       "2              44036939_spinal_canal_stenosis_l3_l4     0.364410  0.328353   \n",
       "3              44036939_spinal_canal_stenosis_l4_l5     0.374329  0.285039   \n",
       "4              44036939_spinal_canal_stenosis_l5_s1     0.323765  0.356296   \n",
       "5    44036939_left_neural_foraminal_narrowing_l1_l2     0.338018  0.357842   \n",
       "6    44036939_left_neural_foraminal_narrowing_l2_l3     0.355018  0.345650   \n",
       "7    44036939_left_neural_foraminal_narrowing_l3_l4     0.336803  0.339710   \n",
       "8    44036939_left_neural_foraminal_narrowing_l4_l5     0.369527  0.310421   \n",
       "9    44036939_left_neural_foraminal_narrowing_l5_s1     0.324511  0.354080   \n",
       "10  44036939_right_neural_foraminal_narrowing_l1_l2     0.349673  0.346692   \n",
       "11  44036939_right_neural_foraminal_narrowing_l2_l3     0.305199  0.346349   \n",
       "12  44036939_right_neural_foraminal_narrowing_l3_l4     0.334163  0.339846   \n",
       "13  44036939_right_neural_foraminal_narrowing_l4_l5     0.353972  0.319242   \n",
       "14  44036939_right_neural_foraminal_narrowing_l5_s1     0.348945  0.323386   \n",
       "15        44036939_left_subarticular_stenosis_l1_l2     0.320001  0.334792   \n",
       "16        44036939_left_subarticular_stenosis_l2_l3     0.364562  0.354611   \n",
       "17        44036939_left_subarticular_stenosis_l3_l4     0.352349  0.346995   \n",
       "18        44036939_left_subarticular_stenosis_l4_l5     0.335331  0.351148   \n",
       "19        44036939_left_subarticular_stenosis_l5_s1     0.362480  0.318515   \n",
       "20       44036939_right_subarticular_stenosis_l1_l2     0.398080  0.298709   \n",
       "21       44036939_right_subarticular_stenosis_l2_l3     0.328432  0.345869   \n",
       "22       44036939_right_subarticular_stenosis_l3_l4     0.354999  0.349790   \n",
       "23       44036939_right_subarticular_stenosis_l4_l5     0.360246  0.313582   \n",
       "24       44036939_right_subarticular_stenosis_l5_s1     0.344363  0.321940   \n",
       "\n",
       "      severe  \n",
       "0   0.299143  \n",
       "1   0.331044  \n",
       "2   0.307238  \n",
       "3   0.340632  \n",
       "4   0.319938  \n",
       "5   0.304141  \n",
       "6   0.299332  \n",
       "7   0.323488  \n",
       "8   0.320052  \n",
       "9   0.321409  \n",
       "10  0.303636  \n",
       "11  0.348451  \n",
       "12  0.325991  \n",
       "13  0.326786  \n",
       "14  0.327670  \n",
       "15  0.345207  \n",
       "16  0.280827  \n",
       "17  0.300656  \n",
       "18  0.313521  \n",
       "19  0.319005  \n",
       "20  0.303210  \n",
       "21  0.325699  \n",
       "22  0.295211  \n",
       "23  0.326172  \n",
       "24  0.333697  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce76cbc",
   "metadata": {
    "papermill": {
     "duration": 0.008137,
     "end_time": "2024-10-03T19:08:33.957360",
     "exception": false,
     "start_time": "2024-10-03T19:08:33.949223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "modelId": 120206,
     "modelInstanceId": 96019,
     "sourceId": 126474,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 123.285725,
   "end_time": "2024-10-03T19:08:35.290113",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-03T19:06:32.004388",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
