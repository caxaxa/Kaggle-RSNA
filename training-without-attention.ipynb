{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa8a775-2d8e-4c89-a8af-6ada7d39656c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fsspec==2024.6.0\n",
      "  Using cached fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Using cached fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "Installing collected packages: fsspec\n",
      "Successfully installed fsspec-2024.6.0\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "#This is Good Practioce for the moment\n",
    "\n",
    "!rm -rf /opt/conda/lib/python3.10/site-packages/fsspec*\n",
    "!pip install fsspec==2024.6.0 --force-reinstall --no-deps\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b54efa-6b1a-4818-a274-5c71090f7b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease                         \n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \n",
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2267 kB]\n",
      "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [999 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3114 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.7 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1150 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3030 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.8 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1439 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2544 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.7 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\n",
      "Fetched 15.1 MB in 1s (13.4 MB/s)                            \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libdrm-amdgpu1 libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1\n",
      "  libdrm2 libelf1 libgl1 libgl1-amber-dri libgl1-mesa-dri libglapi-mesa\n",
      "  libglvnd0 libglx-mesa0 libglx0 libllvm15 libpciaccess0 libsensors-config\n",
      "  libsensors5 libx11-6 libx11-data libx11-xcb1 libxau6 libxcb-dri2-0\n",
      "  libxcb-dri3-0 libxcb-glx0 libxcb-present0 libxcb-randr0 libxcb-shm0\n",
      "  libxcb-sync1 libxcb-xfixes0 libxcb1 libxdmcp6 libxext6 libxfixes3\n",
      "  libxshmfence1 libxxf86vm1\n",
      "Suggested packages:\n",
      "  pciutils lm-sensors\n",
      "The following NEW packages will be installed:\n",
      "  libdrm-amdgpu1 libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1\n",
      "  libdrm2 libelf1 libgl1 libgl1-amber-dri libgl1-mesa-dri libgl1-mesa-glx\n",
      "  libglapi-mesa libglvnd0 libglx-mesa0 libglx0 libllvm15 libpciaccess0\n",
      "  libsensors-config libsensors5 libx11-6 libx11-data libx11-xcb1 libxau6\n",
      "  libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0 libxcb-randr0\n",
      "  libxcb-shm0 libxcb-sync1 libxcb-xfixes0 libxcb1 libxdmcp6 libxext6\n",
      "  libxfixes3 libxshmfence1 libxxf86vm1\n",
      "0 upgraded, 37 newly installed, 0 to remove and 27 not upgraded.\n",
      "Need to get 40.2 MB of archives.\n",
      "After this operation, 173 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libelf1 amd64 0.186-1build1 [51.0 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdrm-common all 2.4.113-2~ubuntu0.22.04.1 [5450 B]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdrm2 amd64 2.4.113-2~ubuntu0.22.04.1 [38.1 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxau6 amd64 1:1.0.9-1build5 [7634 B]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxdmcp6 amd64 1:1.1.3-0ubuntu5 [10.9 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb1 amd64 1.14-3ubuntu3 [49.0 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libx11-data all 2:1.7.5-1ubuntu0.3 [120 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libx11-6 amd64 2:1.7.5-1ubuntu0.3 [667 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxext6 amd64 2:1.3.4-1build1 [31.8 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdrm-amdgpu1 amd64 2.4.113-2~ubuntu0.22.04.1 [19.9 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpciaccess0 amd64 0.16-3 [19.1 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdrm-intel1 amd64 2.4.113-2~ubuntu0.22.04.1 [66.7 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdrm-nouveau2 amd64 2.4.113-2~ubuntu0.22.04.1 [17.5 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdrm-radeon1 amd64 2.4.113-2~ubuntu0.22.04.1 [21.6 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglapi-mesa amd64 23.2.1-1ubuntu3.1~22.04.2 [37.1 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-amber-dri amd64 21.3.9-0ubuntu1~22.04.1 [4218 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libllvm15 amd64 1:15.0.7-0ubuntu0.22.04.3 [25.4 MB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-dri3-0 amd64 1.14-3ubuntu3 [6968 B]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dri amd64 23.2.1-1ubuntu3.1~22.04.2 [8860 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd0 amd64 1.4.0-1 [73.6 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libx11-xcb1 amd64 2:1.7.5-1ubuntu0.3 [7802 B]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-dri2-0 amd64 1.14-3ubuntu3 [7206 B]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-glx0 amd64 1.14-3ubuntu3 [25.9 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-present0 amd64 1.14-3ubuntu3 [5734 B]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-randr0 amd64 1.14-3ubuntu3 [18.3 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-shm0 amd64 1.14-3ubuntu3 [5780 B]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-sync1 amd64 1.14-3ubuntu3 [9416 B]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xfixes0 amd64 1.14-3ubuntu3 [9996 B]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfixes3 amd64 1:6.0.0-1 [11.7 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxshmfence1 amd64 1.3-1build4 [5394 B]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86vm1 amd64 1:1.1.4-1build3 [10.4 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglx-mesa0 amd64 23.2.1-1ubuntu3.1~22.04.2 [158 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx0 amd64 1.4.0-1 [41.0 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl1 amd64 1.4.0-1 [110 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgl1-mesa-glx amd64 23.0.4-0ubuntu1~22.04.1 [5584 B]\n",
      "Fetched 40.2 MB in 2s (17.3 MB/s)          \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libelf1:amd64.\n",
      "(Reading database ... 14545 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libelf1_0.186-1build1_amd64.deb ...\n",
      "Unpacking libelf1:amd64 (0.186-1build1) ...\n",
      "Selecting previously unselected package libdrm-common.\n",
      "Preparing to unpack .../01-libdrm-common_2.4.113-2~ubuntu0.22.04.1_all.deb ...\n",
      "Unpacking libdrm-common (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libdrm2:amd64.\n",
      "Preparing to unpack .../02-libdrm2_2.4.113-2~ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libdrm2:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libxau6:amd64.\n",
      "Preparing to unpack .../03-libxau6_1%3a1.0.9-1build5_amd64.deb ...\n",
      "Unpacking libxau6:amd64 (1:1.0.9-1build5) ...\n",
      "Selecting previously unselected package libxdmcp6:amd64.\n",
      "Preparing to unpack .../04-libxdmcp6_1%3a1.1.3-0ubuntu5_amd64.deb ...\n",
      "Unpacking libxdmcp6:amd64 (1:1.1.3-0ubuntu5) ...\n",
      "Selecting previously unselected package libxcb1:amd64.\n",
      "Preparing to unpack .../05-libxcb1_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb1:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libx11-data.\n",
      "Preparing to unpack .../06-libx11-data_2%3a1.7.5-1ubuntu0.3_all.deb ...\n",
      "Unpacking libx11-data (2:1.7.5-1ubuntu0.3) ...\n",
      "Selecting previously unselected package libx11-6:amd64.\n",
      "Preparing to unpack .../07-libx11-6_2%3a1.7.5-1ubuntu0.3_amd64.deb ...\n",
      "Unpacking libx11-6:amd64 (2:1.7.5-1ubuntu0.3) ...\n",
      "Selecting previously unselected package libxext6:amd64.\n",
      "Preparing to unpack .../08-libxext6_2%3a1.3.4-1build1_amd64.deb ...\n",
      "Unpacking libxext6:amd64 (2:1.3.4-1build1) ...\n",
      "Selecting previously unselected package libdrm-amdgpu1:amd64.\n",
      "Preparing to unpack .../09-libdrm-amdgpu1_2.4.113-2~ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libdrm-amdgpu1:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libpciaccess0:amd64.\n",
      "Preparing to unpack .../10-libpciaccess0_0.16-3_amd64.deb ...\n",
      "Unpacking libpciaccess0:amd64 (0.16-3) ...\n",
      "Selecting previously unselected package libdrm-intel1:amd64.\n",
      "Preparing to unpack .../11-libdrm-intel1_2.4.113-2~ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libdrm-intel1:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libdrm-nouveau2:amd64.\n",
      "Preparing to unpack .../12-libdrm-nouveau2_2.4.113-2~ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libdrm-nouveau2:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libdrm-radeon1:amd64.\n",
      "Preparing to unpack .../13-libdrm-radeon1_2.4.113-2~ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libdrm-radeon1:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libglapi-mesa:amd64.\n",
      "Preparing to unpack .../14-libglapi-mesa_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
      "Unpacking libglapi-mesa:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
      "Selecting previously unselected package libgl1-amber-dri:amd64.\n",
      "Preparing to unpack .../15-libgl1-amber-dri_21.3.9-0ubuntu1~22.04.1_amd64.deb ...\n",
      "Unpacking libgl1-amber-dri:amd64 (21.3.9-0ubuntu1~22.04.1) ...\n",
      "Selecting previously unselected package libllvm15:amd64.\n",
      "Preparing to unpack .../16-libllvm15_1%3a15.0.7-0ubuntu0.22.04.3_amd64.deb ...\n",
      "Unpacking libllvm15:amd64 (1:15.0.7-0ubuntu0.22.04.3) ...\n",
      "Selecting previously unselected package libsensors-config.\n",
      "Preparing to unpack .../17-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...\n",
      "Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...\n",
      "Selecting previously unselected package libsensors5:amd64.\n",
      "Preparing to unpack .../18-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...\n",
      "Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...\n",
      "Selecting previously unselected package libxcb-dri3-0:amd64.\n",
      "Preparing to unpack .../19-libxcb-dri3-0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-dri3-0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libgl1-mesa-dri:amd64.\n",
      "Preparing to unpack .../20-libgl1-mesa-dri_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
      "Unpacking libgl1-mesa-dri:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
      "Selecting previously unselected package libglvnd0:amd64.\n",
      "Preparing to unpack .../21-libglvnd0_1.4.0-1_amd64.deb ...\n",
      "Unpacking libglvnd0:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libx11-xcb1:amd64.\n",
      "Preparing to unpack .../22-libx11-xcb1_2%3a1.7.5-1ubuntu0.3_amd64.deb ...\n",
      "Unpacking libx11-xcb1:amd64 (2:1.7.5-1ubuntu0.3) ...\n",
      "Selecting previously unselected package libxcb-dri2-0:amd64.\n",
      "Preparing to unpack .../23-libxcb-dri2-0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-dri2-0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxcb-glx0:amd64.\n",
      "Preparing to unpack .../24-libxcb-glx0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-glx0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxcb-present0:amd64.\n",
      "Preparing to unpack .../25-libxcb-present0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-present0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxcb-randr0:amd64.\n",
      "Preparing to unpack .../26-libxcb-randr0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-randr0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxcb-shm0:amd64.\n",
      "Preparing to unpack .../27-libxcb-shm0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-shm0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxcb-sync1:amd64.\n",
      "Preparing to unpack .../28-libxcb-sync1_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-sync1:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxcb-xfixes0:amd64.\n",
      "Preparing to unpack .../29-libxcb-xfixes0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-xfixes0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxfixes3:amd64.\n",
      "Preparing to unpack .../30-libxfixes3_1%3a6.0.0-1_amd64.deb ...\n",
      "Unpacking libxfixes3:amd64 (1:6.0.0-1) ...\n",
      "Selecting previously unselected package libxshmfence1:amd64.\n",
      "Preparing to unpack .../31-libxshmfence1_1.3-1build4_amd64.deb ...\n",
      "Unpacking libxshmfence1:amd64 (1.3-1build4) ...\n",
      "Selecting previously unselected package libxxf86vm1:amd64.\n",
      "Preparing to unpack .../32-libxxf86vm1_1%3a1.1.4-1build3_amd64.deb ...\n",
      "Unpacking libxxf86vm1:amd64 (1:1.1.4-1build3) ...\n",
      "Selecting previously unselected package libglx-mesa0:amd64.\n",
      "Preparing to unpack .../33-libglx-mesa0_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
      "Unpacking libglx-mesa0:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
      "Selecting previously unselected package libglx0:amd64.\n",
      "Preparing to unpack .../34-libglx0_1.4.0-1_amd64.deb ...\n",
      "Unpacking libglx0:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libgl1:amd64.\n",
      "Preparing to unpack .../35-libgl1_1.4.0-1_amd64.deb ...\n",
      "Unpacking libgl1:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
      "Preparing to unpack .../36-libgl1-mesa-glx_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
      "Unpacking libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
      "Setting up libpciaccess0:amd64 (0.16-3) ...\n",
      "Setting up libxau6:amd64 (1:1.0.9-1build5) ...\n",
      "Setting up libxdmcp6:amd64 (1:1.1.3-0ubuntu5) ...\n",
      "Setting up libxcb1:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libxcb-xfixes0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libglvnd0:amd64 (1.4.0-1) ...\n",
      "Setting up libxcb-glx0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libsensors-config (1:3.6.0-7ubuntu1) ...\n",
      "Setting up libxcb-shm0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libxcb-present0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libx11-data (2:1.7.5-1ubuntu0.3) ...\n",
      "Setting up libxcb-sync1:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...\n",
      "Setting up libglapi-mesa:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
      "Setting up libxcb-dri2-0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libxshmfence1:amd64 (1.3-1build4) ...\n",
      "Setting up libxcb-randr0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libllvm15:amd64 (1:15.0.7-0ubuntu0.22.04.3) ...\n",
      "Setting up libx11-6:amd64 (2:1.7.5-1ubuntu0.3) ...\n",
      "Setting up libdrm-common (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Setting up libelf1:amd64 (0.186-1build1) ...\n",
      "Setting up libxcb-dri3-0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libx11-xcb1:amd64 (2:1.7.5-1ubuntu0.3) ...\n",
      "Setting up libxext6:amd64 (2:1.3.4-1build1) ...\n",
      "Setting up libxxf86vm1:amd64 (1:1.1.4-1build3) ...\n",
      "Setting up libxfixes3:amd64 (1:6.0.0-1) ...\n",
      "Setting up libdrm2:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Setting up libdrm-amdgpu1:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Setting up libdrm-nouveau2:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Setting up libdrm-radeon1:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Setting up libdrm-intel1:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Setting up libgl1-mesa-dri:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
      "Setting up libgl1-amber-dri:amd64 (21.3.9-0ubuntu1~22.04.1) ...\n",
      "Setting up libglx-mesa0:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
      "Setting up libglx0:amd64 (1.4.0-1) ...\n",
      "Setting up libgl1:amd64 (1.4.0-1) ...\n",
      "Setting up libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libglib2.0-data shared-mime-info xdg-user-dirs\n",
      "The following NEW packages will be installed:\n",
      "  libglib2.0-0 libglib2.0-data shared-mime-info xdg-user-dirs\n",
      "0 upgraded, 4 newly installed, 0 to remove and 27 not upgraded.\n",
      "Need to get 1978 kB of archives.\n",
      "After this operation, 7664 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.3 [1466 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.3 [4666 B]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]\n",
      "Fetched 1978 kB in 0s (7624 kB/s)      \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libglib2.0-0:amd64.\n",
      "(Reading database ... 15032 files and directories currently installed.)\n",
      "Preparing to unpack .../libglib2.0-0_2.72.4-0ubuntu2.3_amd64.deb ...\n",
      "Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.3) ...\n",
      "Selecting previously unselected package libglib2.0-data.\n",
      "Preparing to unpack .../libglib2.0-data_2.72.4-0ubuntu2.3_all.deb ...\n",
      "Unpacking libglib2.0-data (2.72.4-0ubuntu2.3) ...\n",
      "Selecting previously unselected package shared-mime-info.\n",
      "Preparing to unpack .../shared-mime-info_2.1-2_amd64.deb ...\n",
      "Unpacking shared-mime-info (2.1-2) ...\n",
      "Selecting previously unselected package xdg-user-dirs.\n",
      "Preparing to unpack .../xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...\n",
      "Unpacking xdg-user-dirs (0.17-2ubuntu4) ...\n",
      "Setting up xdg-user-dirs (0.17-2ubuntu4) ...\n",
      "Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.3) ...\n",
      "No schema files found: doing nothing.\n",
      "Setting up libglib2.0-data (2.72.4-0ubuntu2.3) ...\n",
      "Setting up shared-mime-info (2.1-2) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n"
     ]
    }
   ],
   "source": [
    "#install also to vizualize figures\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y libgl1-mesa-glx\n",
    "!sudo apt-get install -y libglib2.0-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2e8525-7039-417e-b57e-be518796bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9ecee34-ddef-4acf-ab8a-d0c7af3417fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the root directory for your Kaggle files\n",
    "rd = './kaggle-files'\n",
    "\n",
    "# Load the main CSV file\n",
    "df = pd.read_csv(f'{rd}/train.csv')\n",
    "df = df.fillna(-100)  # Use -100 to indicate missing labels\n",
    "\n",
    "# Map the labels to integers for multi-class classification\n",
    "label2id = {'Normal/Mild': 0, 'Moderate': 1, 'Severe': 2}\n",
    "df.replace(label2id, inplace=True)\n",
    "\n",
    "# Load the coordinates data\n",
    "coordinates_df = pd.read_csv(f'{rd}/dfc_updated.csv')\n",
    "# Keep only rows where 'slice_number' is not NaN\n",
    "coordinates_df = coordinates_df.dropna(subset=['slice_number'])\n",
    "coordinates_df['slice_number'] = coordinates_df['slice_number'].astype(int)\n",
    "\n",
    "# Load the series descriptions\n",
    "series_description_df = pd.read_csv(f'{rd}/train_series_descriptions.csv')\n",
    "series_description_df['series_description'] = series_description_df['series_description'].str.replace('T2/STIR', 'T2_STIR')\n",
    "\n",
    "# Define constants\n",
    "SERIES_DESCRIPTIONS = ['Sagittal T1', 'Sagittal T2_STIR', 'Axial T2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71d60a01-0b5a-4970-ad85-a3a505aec58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LumbarSpineDataset(Dataset):\n",
    "    def __init__(self, df, coordinates_df, series_description_df, root_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.coordinates_df = coordinates_df\n",
    "        self.series_description_df = series_description_df\n",
    "        self.root_dir = root_dir  # The root directory where images are stored\n",
    "        self.transform = transform\n",
    "\n",
    "        # Get the list of study_ids\n",
    "        self.study_ids = self.df['study_id'].unique()\n",
    "\n",
    "        # List of label columns (assuming all columns except 'study_id' are labels)\n",
    "        self.label_columns = [col for col in df.columns if col != 'study_id']\n",
    "\n",
    "        # Prepare a mapping for images and annotations\n",
    "        self.study_image_paths = self._prepare_image_paths()\n",
    "\n",
    "        # Create a mapping from study_id to labels\n",
    "        self.labels_dict = self._prepare_labels()\n",
    "\n",
    "    def _prepare_image_paths(self):\n",
    "        study_image_paths = {}\n",
    "        for study_id in self.study_ids:\n",
    "            study_image_paths[study_id] = {}\n",
    "            for series_description in SERIES_DESCRIPTIONS:\n",
    "                series_description_clean = series_description.replace('/', '_')\n",
    "                image_dir = os.path.join(self.root_dir, 'cvt_png', str(study_id), series_description_clean)\n",
    "                if os.path.exists(image_dir):\n",
    "                    # Get all images in the directory\n",
    "                    image_paths = sorted(glob.glob(os.path.join(image_dir, '*.png')))\n",
    "                    study_image_paths[study_id][series_description] = image_paths\n",
    "                else:\n",
    "                    # Handle missing series\n",
    "                    study_image_paths[study_id][series_description] = []\n",
    "        return study_image_paths\n",
    "\n",
    "    def _prepare_labels(self):\n",
    "        labels_dict = {}\n",
    "        for idx, row in self.df.iterrows():\n",
    "            study_id = row['study_id']\n",
    "            labels = []\n",
    "            for col in self.label_columns:\n",
    "                label = row[col]\n",
    "                if pd.isnull(label) or label == -100:\n",
    "                    label = -100  # Use -100 for missing labels (ignore_index)\n",
    "                else:\n",
    "                    label = int(label)\n",
    "                labels.append(label)\n",
    "            labels_dict[study_id] = labels\n",
    "        return labels_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.study_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        study_id = self.study_ids[idx]\n",
    "        images = {}\n",
    "        annotations = {}\n",
    "\n",
    "        # Load images for each series description\n",
    "        for series_description in SERIES_DESCRIPTIONS:\n",
    "            image_paths = self.study_image_paths[study_id][series_description]\n",
    "            series_images = []\n",
    "            for img_path in image_paths:\n",
    "                img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                series_images.append(img)\n",
    "            if series_images:\n",
    "                # Stack images along the depth dimension\n",
    "                series_tensor = torch.stack(series_images, dim=0)  # Shape: [num_slices, 1, H, W]\n",
    "            else:\n",
    "                # Handle missing images\n",
    "                series_tensor = torch.zeros((1, 1, 512, 512))  # Placeholder tensor\n",
    "            images[series_description] = series_tensor\n",
    "\n",
    "        # Get labels for the study_id\n",
    "        labels = self.labels_dict[study_id]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.long)  # Use long dtype for CrossEntropyLoss\n",
    "\n",
    "        # Get annotations for the study_id (if needed)\n",
    "        study_annotations = self.coordinates_df[self.coordinates_df['study_id'] == study_id]\n",
    "        for _, row in study_annotations.iterrows():\n",
    "            condition = row['condition']\n",
    "            level = row['level']\n",
    "            x = row['x_scaled']\n",
    "            y = row['y_scaled']\n",
    "            series_description = row['series_description']\n",
    "            slice_number = int(row['slice_number'])\n",
    "            key = f\"{condition}_{level}\"\n",
    "            if key not in annotations:\n",
    "                annotations[key] = {}\n",
    "            if series_description not in annotations[key]:\n",
    "                annotations[key][series_description] = []\n",
    "            annotations[key][series_description].append({\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'slice_number': slice_number\n",
    "            })\n",
    "\n",
    "        # Return a dictionary containing images, labels, and annotations\n",
    "        sample = {\n",
    "            'study_id': study_id,\n",
    "            'images': images,\n",
    "            'labels': labels_tensor,\n",
    "            'annotations': annotations\n",
    "        }\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cefa0b40-fd4b-4763-b82c-a636b9899ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define any transformations if needed\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Adjust mean and std if necessary\n",
    "])\n",
    "\n",
    "# Instantiate the dataset\n",
    "train_dataset = LumbarSpineDataset(\n",
    "    df=df,\n",
    "    coordinates_df=coordinates_df,\n",
    "    series_description_df=series_description_df,\n",
    "    root_dir='./rsna_output',  # Adjust the path as needed\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Create a DataLoader\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=1,  # Adjust batch size as needed\n",
    "    shuffle=True,\n",
    "    num_workers=4,  # Adjust based on your system\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c18c607-b316-4be8-9409-c07832e230b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResNet feature extractor\n",
    "class ResNetFeatureExtractor(nn.Module):\n",
    "    def __init__(self, in_channels=10):\n",
    "        super(ResNetFeatureExtractor, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        # Modify the first convolutional layer to accept in_channels\n",
    "        resnet.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # Extract layers up to layer4 (exclude avgpool and fc layers)\n",
    "        self.features = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu,\n",
    "            resnet.maxpool,\n",
    "            resnet.layer1,\n",
    "            resnet.layer2,\n",
    "            resnet.layer3,\n",
    "            resnet.layer4\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x  # Output shape: [batch_size, 512, H, W]\n",
    "\n",
    "# Define the main model\n",
    "class MultiSeriesSpineModel(nn.Module):\n",
    "    def __init__(self, num_conditions=25, num_classes=3):\n",
    "        super(MultiSeriesSpineModel, self).__init__()\n",
    "\n",
    "        # Feature extractors for each MRI series\n",
    "        self.cnn_sagittal_t1 = ResNetFeatureExtractor(in_channels=10)\n",
    "        self.cnn_sagittal_t2_stir = ResNetFeatureExtractor(in_channels=10)\n",
    "        self.cnn_axial_t2 = ResNetFeatureExtractor(in_channels=10)\n",
    "\n",
    "        # Define attention layers for each series\n",
    "        self.attention_sagittal_t1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.attention_sagittal_t2_stir = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.attention_axial_t2 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Define the final classification layers\n",
    "        combined_feature_size = 512 * 3  # Since we're concatenating features from three models\n",
    "\n",
    "        self.fc1 = nn.Linear(combined_feature_size, 512)\n",
    "        self.fc2 = nn.Linear(512, num_conditions * num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, sagittal_t1, sagittal_t2_stir, axial_t2):\n",
    "        # Forward pass through each ResNet18 model\n",
    "        features_sagittal_t1 = self.cnn_sagittal_t1(sagittal_t1)  # Shape: [batch_size, 512, H, W]\n",
    "        features_sagittal_t2_stir = self.cnn_sagittal_t2_stir(sagittal_t2_stir)\n",
    "        features_axial_t2 = self.cnn_axial_t2(axial_t2)\n",
    "\n",
    "        # Generate attention maps\n",
    "        attention_map_t1 = self.attention_sagittal_t1(features_sagittal_t1)  # Shape: [batch_size, 1, H, W]\n",
    "        attention_map_t2_stir = self.attention_sagittal_t2_stir(features_sagittal_t2_stir)\n",
    "        attention_map_axial = self.attention_axial_t2(features_axial_t2)\n",
    "\n",
    "        # Apply attention\n",
    "        features_sagittal_t1 = features_sagittal_t1 * attention_map_t1  # Element-wise multiplication\n",
    "        features_sagittal_t2_stir = features_sagittal_t2_stir * attention_map_t2_stir\n",
    "        features_axial_t2 = features_axial_t2 * attention_map_axial\n",
    "\n",
    "        # Global average pooling\n",
    "        features_sagittal_t1 = F.adaptive_avg_pool2d(features_sagittal_t1, (1, 1)).view(features_sagittal_t1.size(0), -1)\n",
    "        features_sagittal_t2_stir = F.adaptive_avg_pool2d(features_sagittal_t2_stir, (1, 1)).view(features_sagittal_t2_stir.size(0), -1)\n",
    "        features_axial_t2 = F.adaptive_avg_pool2d(features_axial_t2, (1, 1)).view(features_axial_t2.size(0), -1)\n",
    "\n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat([features_sagittal_t1, features_sagittal_t2_stir, features_axial_t2], dim=1)\n",
    "\n",
    "        # Pass through final classification layers\n",
    "        x = F.relu(self.fc1(combined_features))\n",
    "        x = self.fc2(x)  # Shape: [batch_size, num_conditions * num_classes]\n",
    "        x = x.view(-1, num_conditions, num_classes)  # Reshape to [batch_size, num_conditions, num_classes]\n",
    "        return x  # Return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26e3a38c-1ea4-44ec-be6a-6e2e1f4136ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample slices function\n",
    "def resample_slices(image_tensor, target_slices=10):\n",
    "    \"\"\"\n",
    "    Resample the number of slices to match the target number of slices.\n",
    "    \"\"\"\n",
    "    current_slices = image_tensor.shape[0]\n",
    "\n",
    "    if current_slices == target_slices:\n",
    "        return image_tensor  # No need to resample\n",
    "\n",
    "    # If more slices, downsample to the target number\n",
    "    if current_slices > target_slices:\n",
    "        indices = torch.linspace(0, current_slices - 1, target_slices).long()\n",
    "        return image_tensor[indices]\n",
    "\n",
    "    # If fewer slices, upsample by interpolation\n",
    "    image_tensor = image_tensor.permute(1, 0, 2, 3).unsqueeze(0)  # Shape: [1, channels, slices, H, W]\n",
    "    image_tensor_resized = F.interpolate(\n",
    "        image_tensor,\n",
    "        size=(target_slices, image_tensor.shape[3], image_tensor.shape[4]),\n",
    "        mode='trilinear',\n",
    "        align_corners=False\n",
    "    )\n",
    "    return image_tensor_resized.squeeze(0).permute(1, 0, 2, 3)  # Shape: [slices, channels, H, W]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83260bb8-a7d6-446a-a823-e91e0d2c2e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0.0, path='best_model.pt'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "            path (str): Path to save the best model.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.best_loss:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eedc0326-3bc8-45ee-b0b6-5e3aef8a7db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "num_conditions = len(train_dataset.label_columns)\n",
    "num_classes = 3\n",
    "model = MultiSeriesSpineModel(num_conditions=num_conditions, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# # Load the trained model's state_dict\n",
    "# model_save_path = 'multi_series_spine_model.pth'\n",
    "# model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)  # Use ignore_index to ignore missing labels\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bafac832-e0f1-4490-8199-865f235de16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define transformations with data augmentation if desired\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Adjust mean and std if necessary\n",
    "])\n",
    "\n",
    "# Instantiate the full dataset\n",
    "full_dataset = LumbarSpineDataset(\n",
    "    df=df,\n",
    "    coordinates_df=coordinates_df,\n",
    "    series_description_df=series_description_df,\n",
    "    root_dir='./rsna_output',  # Adjust the path as needed\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Define number of conditions and classes\n",
    "num_conditions = len(full_dataset.label_columns)  # 25 in your case\n",
    "num_classes = 3  # 'Normal/Mild': 0, 'Moderate': 1, 'Severe': 2\n",
    "\n",
    "# Initialize K-Fold\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3c6c44a-46ac-4802-9ebc-ef8f3399dc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f57c9-c415-415f-98de-138fd1f70961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 1/50: 100%|██████████| 1580/1580 [05:17<00:00,  4.98batch/s, Loss=0.2833]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 1/50 Training Loss: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 1/50 Validation Loss: 1.0048\n",
      "Validation loss decreased (1.004845 --> 1.004845).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 2/50: 100%|██████████| 1580/1580 [05:21<00:00,  4.92batch/s, Loss=0.3006]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 2/50 Training Loss: 0.5760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 2/50 Validation Loss: 0.9363\n",
      "Validation loss decreased (0.936295 --> 0.936295).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 3/50:   0%|          | 0/1580 [00:00<?, ?batch/s]"
     ]
    }
   ],
   "source": [
    "# Training loop with Cross-Validation and Early Stopping\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(full_dataset)):\n",
    "    print(f'\\n=== Fold {fold + 1}/{n_splits} ===')\n",
    "\n",
    "    # Create subsets for training and validation\n",
    "    train_subset = Subset(full_dataset, train_idx)\n",
    "    val_subset = Subset(full_dataset, val_idx)\n",
    "\n",
    "    # Create DataLoaders with increased batch size\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_subset,\n",
    "        batch_size=1,  # Increased from 1\n",
    "        shuffle=True,\n",
    "        num_workers=4,  # Adjust based on your system\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        dataset=val_subset,\n",
    "        batch_size=1,  # Increased from 1\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Instantiate a new model for each fold\n",
    "    model = MultiSeriesSpineModel(num_conditions=num_conditions, num_classes=num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)  # Using AdamW with higher lr\n",
    "\n",
    "    # Define a learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "    # Initialize EarlyStopping\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True, path=f'best_model_fold_{fold + 1}.pt')\n",
    "\n",
    "    # Define number of epochs\n",
    "    num_epochs = 50  # Increased epochs to allow early stopping\n",
    "\n",
    "    # Lists to store epoch-wise loss for plotting\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Fold {fold + 1} Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            # Extract images and labels from the batch\n",
    "            images = batch['images']\n",
    "            labels = batch['labels']  # Tensor of shape [num_conditions]\n",
    "\n",
    "            # Get the image tensors\n",
    "            sagittal_t1 = images['Sagittal T1'].squeeze(0)  # Shape: [num_slices, 1, H, W]\n",
    "            sagittal_t2_stir = images['Sagittal T2_STIR'].squeeze(0)\n",
    "            axial_t2 = images['Axial T2'].squeeze(0)\n",
    "\n",
    "            # Resample slices to 10\n",
    "            sagittal_t1 = resample_slices(sagittal_t1, target_slices=10)\n",
    "            sagittal_t2_stir = resample_slices(sagittal_t2_stir, target_slices=10)\n",
    "            axial_t2 = resample_slices(axial_t2, target_slices=10)\n",
    "\n",
    "            # Remove singleton channel dimension if present\n",
    "            sagittal_t1 = sagittal_t1.squeeze(1)  # Shape: [10, H, W]\n",
    "            sagittal_t2_stir = sagittal_t2_stir.squeeze(1)\n",
    "            axial_t2 = axial_t2.squeeze(1)\n",
    "\n",
    "            # Add batch dimension and move to device\n",
    "            sagittal_t1 = sagittal_t1.unsqueeze(0).to(device)  # Shape: [1, 10, H, W]\n",
    "            sagittal_t2_stir = sagittal_t2_stir.unsqueeze(0).to(device)\n",
    "            axial_t2 = axial_t2.unsqueeze(0).to(device)\n",
    "\n",
    "            # Prepare labels tensor and move to device\n",
    "            labels_tensor = labels.unsqueeze(0).to(device)  # Shape: [1, num_conditions]\n",
    "\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(sagittal_t1, sagittal_t2_stir, axial_t2)  # Shape: [1, num_conditions, num_classes]\n",
    "\n",
    "            # Reshape outputs and labels\n",
    "            outputs = outputs.view(-1, num_classes)       # Shape: [num_conditions, num_classes]\n",
    "            labels_tensor = labels_tensor.view(-1)        # Shape: [num_conditions]\n",
    "\n",
    "            # Compute loss\n",
    "            total_loss = criterion(outputs, labels_tensor)\n",
    "\n",
    "            # Backward pass\n",
    "            total_loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            # Optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update loss\n",
    "            epoch_loss += total_loss.item()\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({'Loss': f'{total_loss.item():.4f}'})\n",
    "\n",
    "        # Calculate average training loss\n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(f\"Fold {fold + 1} Epoch {epoch+1}/{num_epochs} Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch['images']\n",
    "                labels = batch['labels']\n",
    "\n",
    "                sagittal_t1 = images['Sagittal T1'].squeeze(0)\n",
    "                sagittal_t2_stir = images['Sagittal T2_STIR'].squeeze(0)\n",
    "                axial_t2 = images['Axial T2'].squeeze(0)\n",
    "\n",
    "                sagittal_t1 = resample_slices(sagittal_t1, target_slices=10)\n",
    "                sagittal_t2_stir = resample_slices(sagittal_t2_stir, target_slices=10)\n",
    "                axial_t2 = resample_slices(axial_t2, target_slices=10)\n",
    "\n",
    "                sagittal_t1 = sagittal_t1.squeeze(1)\n",
    "                sagittal_t2_stir = sagittal_t2_stir.squeeze(1)\n",
    "                axial_t2 = axial_t2.squeeze(1)\n",
    "\n",
    "                sagittal_t1 = sagittal_t1.unsqueeze(0).to(device)\n",
    "                sagittal_t2_stir = sagittal_t2_stir.unsqueeze(0).to(device)\n",
    "                axial_t2 = axial_t2.unsqueeze(0).to(device)\n",
    "\n",
    "                labels_tensor = labels.unsqueeze(0).to(device)\n",
    "\n",
    "                outputs = model(sagittal_t1, sagittal_t2_stir, axial_t2)\n",
    "                outputs = outputs.view(-1, num_classes)\n",
    "                labels_tensor = labels_tensor.view(-1)\n",
    "\n",
    "                loss = criterion(outputs, labels_tensor)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels_tensor.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f\"Fold {fold + 1} Epoch {epoch+1}/{num_epochs} Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Update scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Check early stopping\n",
    "        early_stopping(avg_val_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1} for fold {fold + 1}\")\n",
    "            break\n",
    "\n",
    "    # Load the best model for the current fold\n",
    "    model.load_state_dict(torch.load(f'best_model_fold_{fold + 1}.pt'))\n",
    "\n",
    "    # Evaluation on the validation set\n",
    "    model.eval()\n",
    "    fold_val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['images']\n",
    "            labels = batch['labels']\n",
    "\n",
    "            sagittal_t1 = images['Sagittal T1'].squeeze(0)\n",
    "            sagittal_t2_stir = images['Sagittal T2_STIR'].squeeze(0)\n",
    "            axial_t2 = images['Axial T2'].squeeze(0)\n",
    "\n",
    "            sagittal_t1 = resample_slices(sagittal_t1, target_slices=10)\n",
    "            sagittal_t2_stir = resample_slices(sagittal_t2_stir, target_slices=10)\n",
    "            axial_t2 = resample_slices(axial_t2, target_slices=10)\n",
    "\n",
    "            sagittal_t1 = sagittal_t1.squeeze(1)\n",
    "            sagittal_t2_stir = sagittal_t2_stir.squeeze(1)\n",
    "            axial_t2 = axial_t2.squeeze(1)\n",
    "\n",
    "            sagittal_t1 = sagittal_t1.unsqueeze(0).to(device)\n",
    "            sagittal_t2_stir = sagittal_t2_stir.unsqueeze(0).to(device)\n",
    "            axial_t2 = axial_t2.unsqueeze(0).to(device)\n",
    "\n",
    "            labels_tensor = labels.unsqueeze(0).to(device)\n",
    "\n",
    "            outputs = model(sagittal_t1, sagittal_t2_stir, axial_t2)\n",
    "            outputs = outputs.view(-1, num_classes)\n",
    "            labels_tensor = labels_tensor.view(-1)\n",
    "\n",
    "            loss = criterion(outputs, labels_tensor)\n",
    "            fold_val_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels_tensor.cpu().numpy())\n",
    "\n",
    "    avg_fold_val_loss = fold_val_loss / len(val_loader)\n",
    "    print(f\"Fold {fold + 1} Best Validation Loss: {avg_fold_val_loss:.4f}\")\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    print(f\"Fold {fold + 1} Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Fold {fold + 1} Validation F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Store metrics\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_f1_scores.append(f1)\n",
    "    fold_val_losses.append(avg_fold_val_loss)\n",
    "\n",
    "    # Plot training and validation loss for the current fold\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Fold {fold + 1} Loss Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Clean up for the next fold\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# After all folds\n",
    "print(\"\\n=== Cross-Validation Results ===\")\n",
    "print(f\"Average Validation Loss: {np.mean(fold_val_losses):.4f} ± {np.std(fold_val_losses):.4f}\")\n",
    "print(f\"Average Validation Accuracy: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n",
    "print(f\"Average Validation F1 Score: {np.mean(fold_f1_scores):.4f} ± {np.std(fold_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a656b575-b21d-4621-9eb4-e74e6e5142c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3528dba-8cfe-4cd2-a7da-d0f4f4378be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d75b6-a9e5-48f1-9620-bc15747f7052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72780fd-3501-4742-b350-f59673338908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81676ba5-4374-4691-acd7-db15f793d89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  38%|███▊      | 760/1975 [02:13<04:13,  4.80batch/s, Loss=0.3511]"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10  # Define the number of epochs\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        # Extract images and labels from the batch\n",
    "        images = batch['images']\n",
    "        labels = batch['labels']  # Tensor of shape [num_conditions]\n",
    "\n",
    "        # Get the image tensors\n",
    "        sagittal_t1 = images['Sagittal T1'].squeeze(0)  # Shape: [num_slices, 1, H, W]\n",
    "        sagittal_t2_stir = images['Sagittal T2_STIR'].squeeze(0)\n",
    "        axial_t2 = images['Axial T2'].squeeze(0)\n",
    "\n",
    "        # Resample slices to 10\n",
    "        sagittal_t1 = resample_slices(sagittal_t1, target_slices=10)\n",
    "        sagittal_t2_stir = resample_slices(sagittal_t2_stir, target_slices=10)\n",
    "        axial_t2 = resample_slices(axial_t2, target_slices=10)\n",
    "\n",
    "        # Remove singleton channel dimension if present\n",
    "        sagittal_t1 = sagittal_t1.squeeze(1)  # Shape: [10, H, W]\n",
    "        sagittal_t2_stir = sagittal_t2_stir.squeeze(1)\n",
    "        axial_t2 = axial_t2.squeeze(1)\n",
    "\n",
    "        # Add batch dimension and move to device\n",
    "        sagittal_t1 = sagittal_t1.unsqueeze(0).to(device)  # Shape: [1, 10, H, W]\n",
    "        sagittal_t2_stir = sagittal_t2_stir.unsqueeze(0).to(device)\n",
    "        axial_t2 = axial_t2.unsqueeze(0).to(device)\n",
    "\n",
    "        # Prepare labels tensor and move to device\n",
    "        labels_tensor = labels.unsqueeze(0).to(device)  # Shape: [1, num_conditions]\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(sagittal_t1, sagittal_t2_stir, axial_t2)  # Shape: [1, num_conditions, num_classes]\n",
    "\n",
    "        # Reshape outputs and labels\n",
    "        outputs = outputs.view(-1, num_classes)       # Shape: [num_conditions, num_classes]\n",
    "        labels_tensor = labels_tensor.view(-1)        # Shape: [num_conditions]\n",
    "\n",
    "        # Compute loss\n",
    "        total_loss = criterion(outputs, labels_tensor)\n",
    "\n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update loss\n",
    "        epoch_loss += total_loss.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({'Loss': f'{total_loss.item():.4f}'})\n",
    "\n",
    "    # Epoch summary\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90573240-4869-40d9-b4fd-30ccc88801d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model's state_dict\n",
    "model_save_path = 'multi_series_spine_model.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef34c129-3ffa-45ef-8edd-058ace6724bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4db0c-7c47-426e-aa84-e53f43257251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ed61b1-ca4d-4017-8304-5b060ba9ae15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c37e366-09d3-41d8-b1a7-141f31c5d950",
   "metadata": {},
   "source": [
    "\n",
    "### Objective:\n",
    "We want to plot an annotated axial slice image from our dataset. The annotations come from the `coordinates_df`, which contains x, y coordinates and additional information about the study, including the `series_id`, `instance_number`, `condition`, and `level`. These annotations represent the specific slices and the associated condition-level severity we're trying to classify/estimate.\n",
    "\n",
    "### Key Points:\n",
    "1. **Data Sources**:\n",
    "   - **`df`**: This contains the labels for `condition` and `level` across different spinal areas for each `study_id`.\n",
    "   - **`coordinates_df`**: This contains the x, y coordinates, `series_id`, `instance_number`, `condition`, and `level` related to each `study_id`.\n",
    "   - **`series_description_df`**: This maps the `series_id` to its respective `series_description` (e.g., 'Axial T2', 'Sagittal T1').\n",
    "\n",
    "2. **Image Path Mapping**:\n",
    "   - From `coordinates_df`, we need to extract the `study_id`, `series_id`, and `instance_number` to locate the corresponding axial image. \n",
    "   - The image path is generated using:\n",
    "     ```python\n",
    "     image_path = f'./rsna_output/cvt_png/{study_id}/{series_description}/{instance_number:03d}.png'\n",
    "     ```\n",
    "     where `series_description` is derived from the `series_id` using the `series_description_df`.\n",
    "\n",
    "3. **DataLoader Responsibilities**:\n",
    "   - The DataLoader needs to provide the required information (`study_id`, `series_id`, `instance_number`, `x`, `y`) to correctly map images and annotations.\n",
    "   - For slices without annotations, the model should focus on 'no annotation' data.\n",
    "\n",
    "### Process Flow:\n",
    "1. **Fetch Image and Annotations**:\n",
    "   - For each study (`study_id`), find the `x`, `y` coordinates from `coordinates_df`.\n",
    "   - Get the corresponding `series_id` and map it to a `series_description` using `series_description_df`.\n",
    "   - Locate the slice image using `series_description` and `instance_number`.\n",
    "\n",
    "2. **Plotting**:\n",
    "   - Display the axial slice image with a bounding box drawn around the `x`, `y` coordinates for the annotation.\n",
    "   - Display the label for the corresponding `condition` and `level`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a18821-1403-4841-98ea-0ab8d43b5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Create dummy data to simulate model input\n",
    "# batch_size = 2\n",
    "# dummy_sagittal_t1 = torch.randn(batch_size, 10, 512, 512)  # 10 slices for Sagittal T1\n",
    "# dummy_sagittal_t2_stir = torch.randn(batch_size, 10, 512, 512)  # 10 slices for Sagittal T2/STIR\n",
    "# dummy_axial_t2 = torch.randn(batch_size, 10, 512, 512)  # 10 slices for Axial T2\n",
    "\n",
    "# # Pass through the model to get a forward pass\n",
    "# condition_pred, coord_pred = model(dummy_sagittal_t1, dummy_sagittal_t2_stir, dummy_axial_t2)\n",
    "\n",
    "# # Create the computational graph\n",
    "# dot = make_dot((condition_pred, coord_pred), params=dict(model.named_parameters()))\n",
    "\n",
    "# # Render to a file and display it\n",
    "# dot.render(\"model_diagram\", format=\"png\")  # Save as PNG\n",
    "\n",
    "# # Load and display the image\n",
    "# img = Image.open(\"model_diagram.png\")\n",
    "# plt.figure(figsize=(10, 10))  # Increase the figure size for better clarity\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off')  # Hide axes for clarity\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ed8c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fsspec==2024.6.0\n",
      "  Using cached fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Using cached fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "Installing collected packages: fsspec\n",
      "Successfully installed fsspec-2024.6.0\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "#This is Good Practioce for the moment\n",
    "\n",
    "!rm -rf /opt/conda/lib/python3.10/site-packages/fsspec*\n",
    "!pip install fsspec==2024.6.0 --force-reinstall --no-deps\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e603287f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease                         \n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \n",
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2267 kB]\n",
      "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [999 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3114 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.7 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1150 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3030 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.8 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1439 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2544 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.7 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\n",
      "Fetched 15.1 MB in 1s (13.4 MB/s)                            \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libdrm-amdgpu1 libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1\n",
      "  libdrm2 libelf1 libgl1 libgl1-amber-dri libgl1-mesa-dri libglapi-mesa\n",
      "  libglvnd0 libglx-mesa0 libglx0 libllvm15 libpciaccess0 libsensors-config\n",
      "  libsensors5 libx11-6 libx11-data libx11-xcb1 libxau6 libxcb-dri2-0\n",
      "  libxcb-dri3-0 libxcb-glx0 libxcb-present0 libxcb-randr0 libxcb-shm0\n",
      "  libxcb-sync1 libxcb-xfixes0 libxcb1 libxdmcp6 libxext6 libxfixes3\n",
      "  libxshmfence1 libxxf86vm1\n",
      "Suggested packages:\n",
      "  pciutils lm-sensors\n",
      "The following NEW packages will be installed:\n",
      "  libdrm-amdgpu1 libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1\n",
      "  libdrm2 libelf1 libgl1 libgl1-amber-dri libgl1-mesa-dri libgl1-mesa-glx\n",
      "  libglapi-mesa libglvnd0 libglx-mesa0 libglx0 libllvm15 libpciaccess0\n",
      "  libsensors-config libsensors5 libx11-6 libx11-data libx11-xcb1 libxau6\n",
      "  libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0 libxcb-randr0\n",
      "  libxcb-shm0 libxcb-sync1 libxcb-xfixes0 libxcb1 libxdmcp6 libxext6\n",
      "  libxfixes3 libxshmfence1 libxxf86vm1\n",
      "0 upgraded, 37 newly installed, 0 to remove and 27 not upgraded.\n",
      "Need to get 40.2 MB of archives.\n",
      "After this operation, 173 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libelf1 amd64 0.186-1build1 [51.0 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdrm-common all 2.4.113-2~ubuntu0.22.04.1 [5450 B]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdrm2 amd64 2.4.113-2~ubuntu0.22.04.1 [38.1 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxau6 amd64 1:1.0.9-1build5 [7634 B]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxdmcp6 amd64 1:1.1.3-0ubuntu5 [10.9 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb1 amd64 1.14-3ubuntu3 [49.0 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libx11-data all 2:1.7.5-1ubuntu0.3 [120 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libx11-6 amd64 2:1.7.5-1ubuntu0.3 [667 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxext6 amd64 2:1.3.4-1build1 [31.8 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdrm-amdgpu1 amd64 2.4.113-2~ubuntu0.22.04.1 [19.9 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpciaccess0 amd64 0.16-3 [19.1 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdrm-intel1 amd64 2.4.113-2~ubuntu0.22.04.1 [66.7 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdrm-nouveau2 amd64 2.4.113-2~ubuntu0.22.04.1 [17.5 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdrm-radeon1 amd64 2.4.113-2~ubuntu0.22.04.1 [21.6 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglapi-mesa amd64 23.2.1-1ubuntu3.1~22.04.2 [37.1 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-amber-dri amd64 21.3.9-0ubuntu1~22.04.1 [4218 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libllvm15 amd64 1:15.0.7-0ubuntu0.22.04.3 [25.4 MB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors-config all 1:3.6.0-7ubuntu1 [5274 B]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsensors5 amd64 1:3.6.0-7ubuntu1 [26.3 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-dri3-0 amd64 1.14-3ubuntu3 [6968 B]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dri amd64 23.2.1-1ubuntu3.1~22.04.2 [8860 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd0 amd64 1.4.0-1 [73.6 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libx11-xcb1 amd64 2:1.7.5-1ubuntu0.3 [7802 B]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-dri2-0 amd64 1.14-3ubuntu3 [7206 B]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-glx0 amd64 1.14-3ubuntu3 [25.9 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-present0 amd64 1.14-3ubuntu3 [5734 B]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-randr0 amd64 1.14-3ubuntu3 [18.3 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-shm0 amd64 1.14-3ubuntu3 [5780 B]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-sync1 amd64 1.14-3ubuntu3 [9416 B]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xfixes0 amd64 1.14-3ubuntu3 [9996 B]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfixes3 amd64 1:6.0.0-1 [11.7 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxshmfence1 amd64 1.3-1build4 [5394 B]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86vm1 amd64 1:1.1.4-1build3 [10.4 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglx-mesa0 amd64 23.2.1-1ubuntu3.1~22.04.2 [158 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx0 amd64 1.4.0-1 [41.0 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl1 amd64 1.4.0-1 [110 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgl1-mesa-glx amd64 23.0.4-0ubuntu1~22.04.1 [5584 B]\n",
      "Fetched 40.2 MB in 2s (17.3 MB/s)          \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libelf1:amd64.\n",
      "(Reading database ... 14545 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libelf1_0.186-1build1_amd64.deb ...\n",
      "Unpacking libelf1:amd64 (0.186-1build1) ...\n",
      "Selecting previously unselected package libdrm-common.\n",
      "Preparing to unpack .../01-libdrm-common_2.4.113-2~ubuntu0.22.04.1_all.deb ...\n",
      "Unpacking libdrm-common (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libdrm2:amd64.\n",
      "Preparing to unpack .../02-libdrm2_2.4.113-2~ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libdrm2:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libxau6:amd64.\n",
      "Preparing to unpack .../03-libxau6_1%3a1.0.9-1build5_amd64.deb ...\n",
      "Unpacking libxau6:amd64 (1:1.0.9-1build5) ...\n",
      "Selecting previously unselected package libxdmcp6:amd64.\n",
      "Preparing to unpack .../04-libxdmcp6_1%3a1.1.3-0ubuntu5_amd64.deb ...\n",
      "Unpacking libxdmcp6:amd64 (1:1.1.3-0ubuntu5) ...\n",
      "Selecting previously unselected package libxcb1:amd64.\n",
      "Preparing to unpack .../05-libxcb1_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb1:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libx11-data.\n",
      "Preparing to unpack .../06-libx11-data_2%3a1.7.5-1ubuntu0.3_all.deb ...\n",
      "Unpacking libx11-data (2:1.7.5-1ubuntu0.3) ...\n",
      "Selecting previously unselected package libx11-6:amd64.\n",
      "Preparing to unpack .../07-libx11-6_2%3a1.7.5-1ubuntu0.3_amd64.deb ...\n",
      "Unpacking libx11-6:amd64 (2:1.7.5-1ubuntu0.3) ...\n",
      "Selecting previously unselected package libxext6:amd64.\n",
      "Preparing to unpack .../08-libxext6_2%3a1.3.4-1build1_amd64.deb ...\n",
      "Unpacking libxext6:amd64 (2:1.3.4-1build1) ...\n",
      "Selecting previously unselected package libdrm-amdgpu1:amd64.\n",
      "Preparing to unpack .../09-libdrm-amdgpu1_2.4.113-2~ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libdrm-amdgpu1:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libpciaccess0:amd64.\n",
      "Preparing to unpack .../10-libpciaccess0_0.16-3_amd64.deb ...\n",
      "Unpacking libpciaccess0:amd64 (0.16-3) ...\n",
      "Selecting previously unselected package libdrm-intel1:amd64.\n",
      "Preparing to unpack .../11-libdrm-intel1_2.4.113-2~ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libdrm-intel1:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libdrm-nouveau2:amd64.\n",
      "Preparing to unpack .../12-libdrm-nouveau2_2.4.113-2~ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libdrm-nouveau2:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libdrm-radeon1:amd64.\n",
      "Preparing to unpack .../13-libdrm-radeon1_2.4.113-2~ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libdrm-radeon1:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libglapi-mesa:amd64.\n",
      "Preparing to unpack .../14-libglapi-mesa_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
      "Unpacking libglapi-mesa:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
      "Selecting previously unselected package libgl1-amber-dri:amd64.\n",
      "Preparing to unpack .../15-libgl1-amber-dri_21.3.9-0ubuntu1~22.04.1_amd64.deb ...\n",
      "Unpacking libgl1-amber-dri:amd64 (21.3.9-0ubuntu1~22.04.1) ...\n",
      "Selecting previously unselected package libllvm15:amd64.\n",
      "Preparing to unpack .../16-libllvm15_1%3a15.0.7-0ubuntu0.22.04.3_amd64.deb ...\n",
      "Unpacking libllvm15:amd64 (1:15.0.7-0ubuntu0.22.04.3) ...\n",
      "Selecting previously unselected package libsensors-config.\n",
      "Preparing to unpack .../17-libsensors-config_1%3a3.6.0-7ubuntu1_all.deb ...\n",
      "Unpacking libsensors-config (1:3.6.0-7ubuntu1) ...\n",
      "Selecting previously unselected package libsensors5:amd64.\n",
      "Preparing to unpack .../18-libsensors5_1%3a3.6.0-7ubuntu1_amd64.deb ...\n",
      "Unpacking libsensors5:amd64 (1:3.6.0-7ubuntu1) ...\n",
      "Selecting previously unselected package libxcb-dri3-0:amd64.\n",
      "Preparing to unpack .../19-libxcb-dri3-0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-dri3-0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libgl1-mesa-dri:amd64.\n",
      "Preparing to unpack .../20-libgl1-mesa-dri_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
      "Unpacking libgl1-mesa-dri:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
      "Selecting previously unselected package libglvnd0:amd64.\n",
      "Preparing to unpack .../21-libglvnd0_1.4.0-1_amd64.deb ...\n",
      "Unpacking libglvnd0:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libx11-xcb1:amd64.\n",
      "Preparing to unpack .../22-libx11-xcb1_2%3a1.7.5-1ubuntu0.3_amd64.deb ...\n",
      "Unpacking libx11-xcb1:amd64 (2:1.7.5-1ubuntu0.3) ...\n",
      "Selecting previously unselected package libxcb-dri2-0:amd64.\n",
      "Preparing to unpack .../23-libxcb-dri2-0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-dri2-0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxcb-glx0:amd64.\n",
      "Preparing to unpack .../24-libxcb-glx0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-glx0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxcb-present0:amd64.\n",
      "Preparing to unpack .../25-libxcb-present0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-present0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxcb-randr0:amd64.\n",
      "Preparing to unpack .../26-libxcb-randr0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-randr0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxcb-shm0:amd64.\n",
      "Preparing to unpack .../27-libxcb-shm0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-shm0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxcb-sync1:amd64.\n",
      "Preparing to unpack .../28-libxcb-sync1_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-sync1:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxcb-xfixes0:amd64.\n",
      "Preparing to unpack .../29-libxcb-xfixes0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-xfixes0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxfixes3:amd64.\n",
      "Preparing to unpack .../30-libxfixes3_1%3a6.0.0-1_amd64.deb ...\n",
      "Unpacking libxfixes3:amd64 (1:6.0.0-1) ...\n",
      "Selecting previously unselected package libxshmfence1:amd64.\n",
      "Preparing to unpack .../31-libxshmfence1_1.3-1build4_amd64.deb ...\n",
      "Unpacking libxshmfence1:amd64 (1.3-1build4) ...\n",
      "Selecting previously unselected package libxxf86vm1:amd64.\n",
      "Preparing to unpack .../32-libxxf86vm1_1%3a1.1.4-1build3_amd64.deb ...\n",
      "Unpacking libxxf86vm1:amd64 (1:1.1.4-1build3) ...\n",
      "Selecting previously unselected package libglx-mesa0:amd64.\n",
      "Preparing to unpack .../33-libglx-mesa0_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
      "Unpacking libglx-mesa0:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
      "Selecting previously unselected package libglx0:amd64.\n",
      "Preparing to unpack .../34-libglx0_1.4.0-1_amd64.deb ...\n",
      "Unpacking libglx0:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libgl1:amd64.\n",
      "Preparing to unpack .../35-libgl1_1.4.0-1_amd64.deb ...\n",
      "Unpacking libgl1:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
      "Preparing to unpack .../36-libgl1-mesa-glx_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
      "Unpacking libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
      "Setting up libpciaccess0:amd64 (0.16-3) ...\n",
      "Setting up libxau6:amd64 (1:1.0.9-1build5) ...\n",
      "Setting up libxdmcp6:amd64 (1:1.1.3-0ubuntu5) ...\n",
      "Setting up libxcb1:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libxcb-xfixes0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libglvnd0:amd64 (1.4.0-1) ...\n",
      "Setting up libxcb-glx0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libsensors-config (1:3.6.0-7ubuntu1) ...\n",
      "Setting up libxcb-shm0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libxcb-present0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libx11-data (2:1.7.5-1ubuntu0.3) ...\n",
      "Setting up libxcb-sync1:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libsensors5:amd64 (1:3.6.0-7ubuntu1) ...\n",
      "Setting up libglapi-mesa:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
      "Setting up libxcb-dri2-0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libxshmfence1:amd64 (1.3-1build4) ...\n",
      "Setting up libxcb-randr0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libllvm15:amd64 (1:15.0.7-0ubuntu0.22.04.3) ...\n",
      "Setting up libx11-6:amd64 (2:1.7.5-1ubuntu0.3) ...\n",
      "Setting up libdrm-common (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Setting up libelf1:amd64 (0.186-1build1) ...\n",
      "Setting up libxcb-dri3-0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libx11-xcb1:amd64 (2:1.7.5-1ubuntu0.3) ...\n",
      "Setting up libxext6:amd64 (2:1.3.4-1build1) ...\n",
      "Setting up libxxf86vm1:amd64 (1:1.1.4-1build3) ...\n",
      "Setting up libxfixes3:amd64 (1:6.0.0-1) ...\n",
      "Setting up libdrm2:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Setting up libdrm-amdgpu1:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Setting up libdrm-nouveau2:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Setting up libdrm-radeon1:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Setting up libdrm-intel1:amd64 (2.4.113-2~ubuntu0.22.04.1) ...\n",
      "Setting up libgl1-mesa-dri:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
      "Setting up libgl1-amber-dri:amd64 (21.3.9-0ubuntu1~22.04.1) ...\n",
      "Setting up libglx-mesa0:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
      "Setting up libglx0:amd64 (1.4.0-1) ...\n",
      "Setting up libgl1:amd64 (1.4.0-1) ...\n",
      "Setting up libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libglib2.0-data shared-mime-info xdg-user-dirs\n",
      "The following NEW packages will be installed:\n",
      "  libglib2.0-0 libglib2.0-data shared-mime-info xdg-user-dirs\n",
      "0 upgraded, 4 newly installed, 0 to remove and 27 not upgraded.\n",
      "Need to get 1978 kB of archives.\n",
      "After this operation, 7664 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.3 [1466 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-data all 2.72.4-0ubuntu2.3 [4666 B]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 shared-mime-info amd64 2.1-2 [454 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 xdg-user-dirs amd64 0.17-2ubuntu4 [53.9 kB]\n",
      "Fetched 1978 kB in 0s (7624 kB/s)      \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libglib2.0-0:amd64.\n",
      "(Reading database ... 15032 files and directories currently installed.)\n",
      "Preparing to unpack .../libglib2.0-0_2.72.4-0ubuntu2.3_amd64.deb ...\n",
      "Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.3) ...\n",
      "Selecting previously unselected package libglib2.0-data.\n",
      "Preparing to unpack .../libglib2.0-data_2.72.4-0ubuntu2.3_all.deb ...\n",
      "Unpacking libglib2.0-data (2.72.4-0ubuntu2.3) ...\n",
      "Selecting previously unselected package shared-mime-info.\n",
      "Preparing to unpack .../shared-mime-info_2.1-2_amd64.deb ...\n",
      "Unpacking shared-mime-info (2.1-2) ...\n",
      "Selecting previously unselected package xdg-user-dirs.\n",
      "Preparing to unpack .../xdg-user-dirs_0.17-2ubuntu4_amd64.deb ...\n",
      "Unpacking xdg-user-dirs (0.17-2ubuntu4) ...\n",
      "Setting up xdg-user-dirs (0.17-2ubuntu4) ...\n",
      "Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.3) ...\n",
      "No schema files found: doing nothing.\n",
      "Setting up libglib2.0-data (2.72.4-0ubuntu2.3) ...\n",
      "Setting up shared-mime-info (2.1-2) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n"
     ]
    }
   ],
   "source": [
    "#install also to vizualize figures\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y libgl1-mesa-glx\n",
    "!sudo apt-get install -y libglib2.0-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59896f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the root directory for your Kaggle files\n",
    "rd = './kaggle-files'\n",
    "\n",
    "# Load the main CSV file\n",
    "df = pd.read_csv(f'{rd}/train.csv')\n",
    "df = df.fillna(-100)  # Use -100 to indicate missing labels\n",
    "\n",
    "# Map the labels to integers for multi-class classification\n",
    "label2id = {'Normal/Mild': 0, 'Moderate': 1, 'Severe': 2}\n",
    "df.replace(label2id, inplace=True)\n",
    "\n",
    "# Load the coordinates data\n",
    "coordinates_df = pd.read_csv(f'{rd}/dfc_updated.csv')\n",
    "# Keep only rows where 'slice_number' is not NaN\n",
    "coordinates_df = coordinates_df.dropna(subset=['slice_number'])\n",
    "coordinates_df['slice_number'] = coordinates_df['slice_number'].astype(int)\n",
    "\n",
    "# Load the series descriptions\n",
    "series_description_df = pd.read_csv(f'{rd}/train_series_descriptions.csv')\n",
    "series_description_df['series_description'] = series_description_df['series_description'].str.replace('T2/STIR', 'T2_STIR')\n",
    "\n",
    "# Define constants\n",
    "SERIES_DESCRIPTIONS = ['Sagittal T1', 'Sagittal T2_STIR', 'Axial T2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3088ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LumbarSpineDataset(Dataset):\n",
    "    def __init__(self, df, coordinates_df, series_description_df, root_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.coordinates_df = coordinates_df\n",
    "        self.series_description_df = series_description_df\n",
    "        self.root_dir = root_dir  # The root directory where images are stored\n",
    "        self.transform = transform\n",
    "\n",
    "        # Get the list of study_ids\n",
    "        self.study_ids = self.df['study_id'].unique()\n",
    "\n",
    "        # List of label columns (assuming all columns except 'study_id' are labels)\n",
    "        self.label_columns = [col for col in df.columns if col != 'study_id']\n",
    "\n",
    "        # Prepare a mapping for images and annotations\n",
    "        self.study_image_paths = self._prepare_image_paths()\n",
    "\n",
    "        # Create a mapping from study_id to labels\n",
    "        self.labels_dict = self._prepare_labels()\n",
    "\n",
    "    def _prepare_image_paths(self):\n",
    "        study_image_paths = {}\n",
    "        for study_id in self.study_ids:\n",
    "            study_image_paths[study_id] = {}\n",
    "            for series_description in SERIES_DESCRIPTIONS:\n",
    "                series_description_clean = series_description.replace('/', '_')\n",
    "                image_dir = os.path.join(self.root_dir, 'cvt_png', str(study_id), series_description_clean)\n",
    "                if os.path.exists(image_dir):\n",
    "                    # Get all images in the directory\n",
    "                    image_paths = sorted(glob.glob(os.path.join(image_dir, '*.png')))\n",
    "                    study_image_paths[study_id][series_description] = image_paths\n",
    "                else:\n",
    "                    # Handle missing series\n",
    "                    study_image_paths[study_id][series_description] = []\n",
    "        return study_image_paths\n",
    "\n",
    "    def _prepare_labels(self):\n",
    "        labels_dict = {}\n",
    "        for idx, row in self.df.iterrows():\n",
    "            study_id = row['study_id']\n",
    "            labels = []\n",
    "            for col in self.label_columns:\n",
    "                label = row[col]\n",
    "                if pd.isnull(label) or label == -100:\n",
    "                    label = -100  # Use -100 for missing labels (ignore_index)\n",
    "                else:\n",
    "                    label = int(label)\n",
    "                labels.append(label)\n",
    "            labels_dict[study_id] = labels\n",
    "        return labels_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.study_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        study_id = self.study_ids[idx]\n",
    "        images = {}\n",
    "        annotations = {}\n",
    "\n",
    "        # Load images for each series description\n",
    "        for series_description in SERIES_DESCRIPTIONS:\n",
    "            image_paths = self.study_image_paths[study_id][series_description]\n",
    "            series_images = []\n",
    "            for img_path in image_paths:\n",
    "                img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                series_images.append(img)\n",
    "            if series_images:\n",
    "                # Stack images along the depth dimension\n",
    "                series_tensor = torch.stack(series_images, dim=0)  # Shape: [num_slices, 1, H, W]\n",
    "            else:\n",
    "                # Handle missing images\n",
    "                series_tensor = torch.zeros((1, 1, 512, 512))  # Placeholder tensor\n",
    "            images[series_description] = series_tensor\n",
    "\n",
    "        # Get labels for the study_id\n",
    "        labels = self.labels_dict[study_id]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.long)  # Use long dtype for CrossEntropyLoss\n",
    "\n",
    "        # Get annotations for the study_id (if needed)\n",
    "        study_annotations = self.coordinates_df[self.coordinates_df['study_id'] == study_id]\n",
    "        for _, row in study_annotations.iterrows():\n",
    "            condition = row['condition']\n",
    "            level = row['level']\n",
    "            x = row['x_scaled']\n",
    "            y = row['y_scaled']\n",
    "            series_description = row['series_description']\n",
    "            slice_number = int(row['slice_number'])\n",
    "            key = f\"{condition}_{level}\"\n",
    "            if key not in annotations:\n",
    "                annotations[key] = {}\n",
    "            if series_description not in annotations[key]:\n",
    "                annotations[key][series_description] = []\n",
    "            annotations[key][series_description].append({\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'slice_number': slice_number\n",
    "            })\n",
    "\n",
    "        # Return a dictionary containing images, labels, and annotations\n",
    "        sample = {\n",
    "            'study_id': study_id,\n",
    "            'images': images,\n",
    "            'labels': labels_tensor,\n",
    "            'annotations': annotations\n",
    "        }\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe0eea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define any transformations if needed\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Adjust mean and std if necessary\n",
    "])\n",
    "\n",
    "# Instantiate the dataset\n",
    "train_dataset = LumbarSpineDataset(\n",
    "    df=df,\n",
    "    coordinates_df=coordinates_df,\n",
    "    series_description_df=series_description_df,\n",
    "    root_dir='./rsna_output',  # Adjust the path as needed\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Create a DataLoader\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=1,  # Adjust batch size as needed\n",
    "    shuffle=True,\n",
    "    num_workers=4,  # Adjust based on your system\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24ac4c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResNet feature extractor\n",
    "class ResNetFeatureExtractor(nn.Module):\n",
    "    def __init__(self, in_channels=10):\n",
    "        super(ResNetFeatureExtractor, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        # Modify the first convolutional layer to accept in_channels\n",
    "        resnet.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # Extract layers up to layer4 (exclude avgpool and fc layers)\n",
    "        self.features = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu,\n",
    "            resnet.maxpool,\n",
    "            resnet.layer1,\n",
    "            resnet.layer2,\n",
    "            resnet.layer3,\n",
    "            resnet.layer4\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x  # Output shape: [batch_size, 512, H, W]\n",
    "\n",
    "# Define the main model\n",
    "class MultiSeriesSpineModel(nn.Module):\n",
    "    def __init__(self, num_conditions=25, num_classes=3):\n",
    "        super(MultiSeriesSpineModel, self).__init__()\n",
    "\n",
    "        # Feature extractors for each MRI series\n",
    "        self.cnn_sagittal_t1 = ResNetFeatureExtractor(in_channels=10)\n",
    "        self.cnn_sagittal_t2_stir = ResNetFeatureExtractor(in_channels=10)\n",
    "        self.cnn_axial_t2 = ResNetFeatureExtractor(in_channels=10)\n",
    "\n",
    "        # Define attention layers for each series\n",
    "        self.attention_sagittal_t1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.attention_sagittal_t2_stir = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.attention_axial_t2 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Define the final classification layers\n",
    "        combined_feature_size = 512 * 3  # Since we're concatenating features from three models\n",
    "\n",
    "        self.fc1 = nn.Linear(combined_feature_size, 512)\n",
    "        self.fc2 = nn.Linear(512, num_conditions * num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, sagittal_t1, sagittal_t2_stir, axial_t2):\n",
    "        # Forward pass through each ResNet18 model\n",
    "        features_sagittal_t1 = self.cnn_sagittal_t1(sagittal_t1)  # Shape: [batch_size, 512, H, W]\n",
    "        features_sagittal_t2_stir = self.cnn_sagittal_t2_stir(sagittal_t2_stir)\n",
    "        features_axial_t2 = self.cnn_axial_t2(axial_t2)\n",
    "\n",
    "        # Generate attention maps\n",
    "        attention_map_t1 = self.attention_sagittal_t1(features_sagittal_t1)  # Shape: [batch_size, 1, H, W]\n",
    "        attention_map_t2_stir = self.attention_sagittal_t2_stir(features_sagittal_t2_stir)\n",
    "        attention_map_axial = self.attention_axial_t2(features_axial_t2)\n",
    "\n",
    "        # Apply attention\n",
    "        features_sagittal_t1 = features_sagittal_t1 * attention_map_t1  # Element-wise multiplication\n",
    "        features_sagittal_t2_stir = features_sagittal_t2_stir * attention_map_t2_stir\n",
    "        features_axial_t2 = features_axial_t2 * attention_map_axial\n",
    "\n",
    "        # Global average pooling\n",
    "        features_sagittal_t1 = F.adaptive_avg_pool2d(features_sagittal_t1, (1, 1)).view(features_sagittal_t1.size(0), -1)\n",
    "        features_sagittal_t2_stir = F.adaptive_avg_pool2d(features_sagittal_t2_stir, (1, 1)).view(features_sagittal_t2_stir.size(0), -1)\n",
    "        features_axial_t2 = F.adaptive_avg_pool2d(features_axial_t2, (1, 1)).view(features_axial_t2.size(0), -1)\n",
    "\n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat([features_sagittal_t1, features_sagittal_t2_stir, features_axial_t2], dim=1)\n",
    "\n",
    "        # Pass through final classification layers\n",
    "        x = F.relu(self.fc1(combined_features))\n",
    "        x = self.fc2(x)  # Shape: [batch_size, num_conditions * num_classes]\n",
    "        x = x.view(-1, num_conditions, num_classes)  # Reshape to [batch_size, num_conditions, num_classes]\n",
    "        return x  # Return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c59c3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample slices function\n",
    "def resample_slices(image_tensor, target_slices=10):\n",
    "    \"\"\"\n",
    "    Resample the number of slices to match the target number of slices.\n",
    "    \"\"\"\n",
    "    current_slices = image_tensor.shape[0]\n",
    "\n",
    "    if current_slices == target_slices:\n",
    "        return image_tensor  # No need to resample\n",
    "\n",
    "    # If more slices, downsample to the target number\n",
    "    if current_slices > target_slices:\n",
    "        indices = torch.linspace(0, current_slices - 1, target_slices).long()\n",
    "        return image_tensor[indices]\n",
    "\n",
    "    # If fewer slices, upsample by interpolation\n",
    "    image_tensor = image_tensor.permute(1, 0, 2, 3).unsqueeze(0)  # Shape: [1, channels, slices, H, W]\n",
    "    image_tensor_resized = F.interpolate(\n",
    "        image_tensor,\n",
    "        size=(target_slices, image_tensor.shape[3], image_tensor.shape[4]),\n",
    "        mode='trilinear',\n",
    "        align_corners=False\n",
    "    )\n",
    "    return image_tensor_resized.squeeze(0).permute(1, 0, 2, 3)  # Shape: [slices, channels, H, W]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3743e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0.0, path='best_model.pt'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "            path (str): Path to save the best model.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.best_loss:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24032e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "num_conditions = len(train_dataset.label_columns)\n",
    "num_classes = 3\n",
    "model = MultiSeriesSpineModel(num_conditions=num_conditions, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# # Load the trained model's state_dict\n",
    "# model_save_path = 'multi_series_spine_model.pth'\n",
    "# model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)  # Use ignore_index to ignore missing labels\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "021ca773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define transformations with data augmentation if desired\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Adjust mean and std if necessary\n",
    "])\n",
    "\n",
    "# Instantiate the full dataset\n",
    "full_dataset = LumbarSpineDataset(\n",
    "    df=df,\n",
    "    coordinates_df=coordinates_df,\n",
    "    series_description_df=series_description_df,\n",
    "    root_dir='./rsna_output',  # Adjust the path as needed\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Define number of conditions and classes\n",
    "num_conditions = len(full_dataset.label_columns)  # 25 in your case\n",
    "num_classes = 3  # 'Normal/Mild': 0, 'Moderate': 1, 'Severe': 2\n",
    "\n",
    "# Initialize K-Fold\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c0e2166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fffeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 1/50: 100%|██████████| 1580/1580 [05:17<00:00,  4.98batch/s, Loss=0.2833]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 1/50 Training Loss: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 1/50 Validation Loss: 1.0048\n",
      "Validation loss decreased (1.004845 --> 1.004845).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 2/50: 100%|██████████| 1580/1580 [05:21<00:00,  4.92batch/s, Loss=0.3006]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 2/50 Training Loss: 0.5760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 2/50 Validation Loss: 0.9363\n",
      "Validation loss decreased (0.936295 --> 0.936295).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 3/50:   0%|          | 0/1580 [00:00<?, ?batch/s]"
     ]
    }
   ],
   "source": [
    "# Training loop with Cross-Validation and Early Stopping\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(full_dataset)):\n",
    "    print(f'\\n=== Fold {fold + 1}/{n_splits} ===')\n",
    "\n",
    "    # Create subsets for training and validation\n",
    "    train_subset = Subset(full_dataset, train_idx)\n",
    "    val_subset = Subset(full_dataset, val_idx)\n",
    "\n",
    "    # Create DataLoaders with increased batch size\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_subset,\n",
    "        batch_size=1,  # Increased from 1\n",
    "        shuffle=True,\n",
    "        num_workers=4,  # Adjust based on your system\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        dataset=val_subset,\n",
    "        batch_size=1,  # Increased from 1\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Instantiate a new model for each fold\n",
    "    model = MultiSeriesSpineModel(num_conditions=num_conditions, num_classes=num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)  # Using AdamW with higher lr\n",
    "\n",
    "    # Define a learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "    # Initialize EarlyStopping\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True, path=f'best_model_fold_{fold + 1}.pt')\n",
    "\n",
    "    # Define number of epochs\n",
    "    num_epochs = 50  # Increased epochs to allow early stopping\n",
    "\n",
    "    # Lists to store epoch-wise loss for plotting\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Fold {fold + 1} Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            # Extract images and labels from the batch\n",
    "            images = batch['images']\n",
    "            labels = batch['labels']  # Tensor of shape [num_conditions]\n",
    "\n",
    "            # Get the image tensors\n",
    "            sagittal_t1 = images['Sagittal T1'].squeeze(0)  # Shape: [num_slices, 1, H, W]\n",
    "            sagittal_t2_stir = images['Sagittal T2_STIR'].squeeze(0)\n",
    "            axial_t2 = images['Axial T2'].squeeze(0)\n",
    "\n",
    "            # Resample slices to 10\n",
    "            sagittal_t1 = resample_slices(sagittal_t1, target_slices=10)\n",
    "            sagittal_t2_stir = resample_slices(sagittal_t2_stir, target_slices=10)\n",
    "            axial_t2 = resample_slices(axial_t2, target_slices=10)\n",
    "\n",
    "            # Remove singleton channel dimension if present\n",
    "            sagittal_t1 = sagittal_t1.squeeze(1)  # Shape: [10, H, W]\n",
    "            sagittal_t2_stir = sagittal_t2_stir.squeeze(1)\n",
    "            axial_t2 = axial_t2.squeeze(1)\n",
    "\n",
    "            # Add batch dimension and move to device\n",
    "            sagittal_t1 = sagittal_t1.unsqueeze(0).to(device)  # Shape: [1, 10, H, W]\n",
    "            sagittal_t2_stir = sagittal_t2_stir.unsqueeze(0).to(device)\n",
    "            axial_t2 = axial_t2.unsqueeze(0).to(device)\n",
    "\n",
    "            # Prepare labels tensor and move to device\n",
    "            labels_tensor = labels.unsqueeze(0).to(device)  # Shape: [1, num_conditions]\n",
    "\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(sagittal_t1, sagittal_t2_stir, axial_t2)  # Shape: [1, num_conditions, num_classes]\n",
    "\n",
    "            # Reshape outputs and labels\n",
    "            outputs = outputs.view(-1, num_classes)       # Shape: [num_conditions, num_classes]\n",
    "            labels_tensor = labels_tensor.view(-1)        # Shape: [num_conditions]\n",
    "\n",
    "            # Compute loss\n",
    "            total_loss = criterion(outputs, labels_tensor)\n",
    "\n",
    "            # Backward pass\n",
    "            total_loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            # Optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update loss\n",
    "            epoch_loss += total_loss.item()\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({'Loss': f'{total_loss.item():.4f}'})\n",
    "\n",
    "        # Calculate average training loss\n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(f\"Fold {fold + 1} Epoch {epoch+1}/{num_epochs} Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch['images']\n",
    "                labels = batch['labels']\n",
    "\n",
    "                sagittal_t1 = images['Sagittal T1'].squeeze(0)\n",
    "                sagittal_t2_stir = images['Sagittal T2_STIR'].squeeze(0)\n",
    "                axial_t2 = images['Axial T2'].squeeze(0)\n",
    "\n",
    "                sagittal_t1 = resample_slices(sagittal_t1, target_slices=10)\n",
    "                sagittal_t2_stir = resample_slices(sagittal_t2_stir, target_slices=10)\n",
    "                axial_t2 = resample_slices(axial_t2, target_slices=10)\n",
    "\n",
    "                sagittal_t1 = sagittal_t1.squeeze(1)\n",
    "                sagittal_t2_stir = sagittal_t2_stir.squeeze(1)\n",
    "                axial_t2 = axial_t2.squeeze(1)\n",
    "\n",
    "                sagittal_t1 = sagittal_t1.unsqueeze(0).to(device)\n",
    "                sagittal_t2_stir = sagittal_t2_stir.unsqueeze(0).to(device)\n",
    "                axial_t2 = axial_t2.unsqueeze(0).to(device)\n",
    "\n",
    "                labels_tensor = labels.unsqueeze(0).to(device)\n",
    "\n",
    "                outputs = model(sagittal_t1, sagittal_t2_stir, axial_t2)\n",
    "                outputs = outputs.view(-1, num_classes)\n",
    "                labels_tensor = labels_tensor.view(-1)\n",
    "\n",
    "                loss = criterion(outputs, labels_tensor)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels_tensor.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f\"Fold {fold + 1} Epoch {epoch+1}/{num_epochs} Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Update scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Check early stopping\n",
    "        early_stopping(avg_val_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1} for fold {fold + 1}\")\n",
    "            break\n",
    "\n",
    "    # Load the best model for the current fold\n",
    "    model.load_state_dict(torch.load(f'best_model_fold_{fold + 1}.pt'))\n",
    "\n",
    "    # Evaluation on the validation set\n",
    "    model.eval()\n",
    "    fold_val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['images']\n",
    "            labels = batch['labels']\n",
    "\n",
    "            sagittal_t1 = images['Sagittal T1'].squeeze(0)\n",
    "            sagittal_t2_stir = images['Sagittal T2_STIR'].squeeze(0)\n",
    "            axial_t2 = images['Axial T2'].squeeze(0)\n",
    "\n",
    "            sagittal_t1 = resample_slices(sagittal_t1, target_slices=10)\n",
    "            sagittal_t2_stir = resample_slices(sagittal_t2_stir, target_slices=10)\n",
    "            axial_t2 = resample_slices(axial_t2, target_slices=10)\n",
    "\n",
    "            sagittal_t1 = sagittal_t1.squeeze(1)\n",
    "            sagittal_t2_stir = sagittal_t2_stir.squeeze(1)\n",
    "            axial_t2 = axial_t2.squeeze(1)\n",
    "\n",
    "            sagittal_t1 = sagittal_t1.unsqueeze(0).to(device)\n",
    "            sagittal_t2_stir = sagittal_t2_stir.unsqueeze(0).to(device)\n",
    "            axial_t2 = axial_t2.unsqueeze(0).to(device)\n",
    "\n",
    "            labels_tensor = labels.unsqueeze(0).to(device)\n",
    "\n",
    "            outputs = model(sagittal_t1, sagittal_t2_stir, axial_t2)\n",
    "            outputs = outputs.view(-1, num_classes)\n",
    "            labels_tensor = labels_tensor.view(-1)\n",
    "\n",
    "            loss = criterion(outputs, labels_tensor)\n",
    "            fold_val_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels_tensor.cpu().numpy())\n",
    "\n",
    "    avg_fold_val_loss = fold_val_loss / len(val_loader)\n",
    "    print(f\"Fold {fold + 1} Best Validation Loss: {avg_fold_val_loss:.4f}\")\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    print(f\"Fold {fold + 1} Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Fold {fold + 1} Validation F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Store metrics\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_f1_scores.append(f1)\n",
    "    fold_val_losses.append(avg_fold_val_loss)\n",
    "\n",
    "    # Plot training and validation loss for the current fold\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Fold {fold + 1} Loss Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Clean up for the next fold\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# After all folds\n",
    "print(\"\\n=== Cross-Validation Results ===\")\n",
    "print(f\"Average Validation Loss: {np.mean(fold_val_losses):.4f} ± {np.std(fold_val_losses):.4f}\")\n",
    "print(f\"Average Validation Accuracy: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n",
    "print(f\"Average Validation F1 Score: {np.mean(fold_f1_scores):.4f} ± {np.std(fold_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f578d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7116bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to multi_series_spine_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model's state_dict\n",
    "model_save_path = 'multi_series_spine_model.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a161c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6475b307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66594785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  38%|███▊      | 760/1975 [02:13<04:13,  4.80batch/s, Loss=0.3511]"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10  # Define the number of epochs\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        # Extract images and labels from the batch\n",
    "        images = batch['images']\n",
    "        labels = batch['labels']  # Tensor of shape [num_conditions]\n",
    "\n",
    "        # Get the image tensors\n",
    "        sagittal_t1 = images['Sagittal T1'].squeeze(0)  # Shape: [num_slices, 1, H, W]\n",
    "        sagittal_t2_stir = images['Sagittal T2_STIR'].squeeze(0)\n",
    "        axial_t2 = images['Axial T2'].squeeze(0)\n",
    "\n",
    "        # Resample slices to 10\n",
    "        sagittal_t1 = resample_slices(sagittal_t1, target_slices=10)\n",
    "        sagittal_t2_stir = resample_slices(sagittal_t2_stir, target_slices=10)\n",
    "        axial_t2 = resample_slices(axial_t2, target_slices=10)\n",
    "\n",
    "        # Remove singleton channel dimension if present\n",
    "        sagittal_t1 = sagittal_t1.squeeze(1)  # Shape: [10, H, W]\n",
    "        sagittal_t2_stir = sagittal_t2_stir.squeeze(1)\n",
    "        axial_t2 = axial_t2.squeeze(1)\n",
    "\n",
    "        # Add batch dimension and move to device\n",
    "        sagittal_t1 = sagittal_t1.unsqueeze(0).to(device)  # Shape: [1, 10, H, W]\n",
    "        sagittal_t2_stir = sagittal_t2_stir.unsqueeze(0).to(device)\n",
    "        axial_t2 = axial_t2.unsqueeze(0).to(device)\n",
    "\n",
    "        # Prepare labels tensor and move to device\n",
    "        labels_tensor = labels.unsqueeze(0).to(device)  # Shape: [1, num_conditions]\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(sagittal_t1, sagittal_t2_stir, axial_t2)  # Shape: [1, num_conditions, num_classes]\n",
    "\n",
    "        # Reshape outputs and labels\n",
    "        outputs = outputs.view(-1, num_classes)       # Shape: [num_conditions, num_classes]\n",
    "        labels_tensor = labels_tensor.view(-1)        # Shape: [num_conditions]\n",
    "\n",
    "        # Compute loss\n",
    "        total_loss = criterion(outputs, labels_tensor)\n",
    "\n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update loss\n",
    "        epoch_loss += total_loss.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({'Loss': f'{total_loss.item():.4f}'})\n",
    "\n",
    "    # Epoch summary\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bbe083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model's state_dict\n",
    "model_save_path = 'multi_series_spine_model.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f335e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b4c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be5426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42b03dee",
   "metadata": {},
   "source": [
    "\n",
    "### Objective:\n",
    "We want to plot an annotated axial slice image from our dataset. The annotations come from the `coordinates_df`, which contains x, y coordinates and additional information about the study, including the `series_id`, `instance_number`, `condition`, and `level`. These annotations represent the specific slices and the associated condition-level severity we're trying to classify/estimate.\n",
    "\n",
    "### Key Points:\n",
    "1. **Data Sources**:\n",
    "   - **`df`**: This contains the labels for `condition` and `level` across different spinal areas for each `study_id`.\n",
    "   - **`coordinates_df`**: This contains the x, y coordinates, `series_id`, `instance_number`, `condition`, and `level` related to each `study_id`.\n",
    "   - **`series_description_df`**: This maps the `series_id` to its respective `series_description` (e.g., 'Axial T2', 'Sagittal T1').\n",
    "\n",
    "2. **Image Path Mapping**:\n",
    "   - From `coordinates_df`, we need to extract the `study_id`, `series_id`, and `instance_number` to locate the corresponding axial image. \n",
    "   - The image path is generated using:\n",
    "     ```python\n",
    "     image_path = f'./rsna_output/cvt_png/{study_id}/{series_description}/{instance_number:03d}.png'\n",
    "     ```\n",
    "     where `series_description` is derived from the `series_id` using the `series_description_df`.\n",
    "\n",
    "3. **DataLoader Responsibilities**:\n",
    "   - The DataLoader needs to provide the required information (`study_id`, `series_id`, `instance_number`, `x`, `y`) to correctly map images and annotations.\n",
    "   - For slices without annotations, the model should focus on 'no annotation' data.\n",
    "\n",
    "### Process Flow:\n",
    "1. **Fetch Image and Annotations**:\n",
    "   - For each study (`study_id`), find the `x`, `y` coordinates from `coordinates_df`.\n",
    "   - Get the corresponding `series_id` and map it to a `series_description` using `series_description_df`.\n",
    "   - Locate the slice image using `series_description` and `instance_number`.\n",
    "\n",
    "2. **Plotting**:\n",
    "   - Display the axial slice image with a bounding box drawn around the `x`, `y` coordinates for the annotation.\n",
    "   - Display the label for the corresponding `condition` and `level`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d785dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Create dummy data to simulate model input\n",
    "# batch_size = 2\n",
    "# dummy_sagittal_t1 = torch.randn(batch_size, 10, 512, 512)  # 10 slices for Sagittal T1\n",
    "# dummy_sagittal_t2_stir = torch.randn(batch_size, 10, 512, 512)  # 10 slices for Sagittal T2/STIR\n",
    "# dummy_axial_t2 = torch.randn(batch_size, 10, 512, 512)  # 10 slices for Axial T2\n",
    "\n",
    "# # Pass through the model to get a forward pass\n",
    "# condition_pred, coord_pred = model(dummy_sagittal_t1, dummy_sagittal_t2_stir, dummy_axial_t2)\n",
    "\n",
    "# # Create the computational graph\n",
    "# dot = make_dot((condition_pred, coord_pred), params=dict(model.named_parameters()))\n",
    "\n",
    "# # Render to a file and display it\n",
    "# dot.render(\"model_diagram\", format=\"png\")  # Save as PNG\n",
    "\n",
    "# # Load and display the image\n",
    "# img = Image.open(\"model_diagram.png\")\n",
    "# plt.figure(figsize=(10, 10))  # Increase the figure size for better clarity\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off')  # Hide axes for clarity\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
