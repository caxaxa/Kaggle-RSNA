{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df27ede-34b3-4092-91c9-6a96260c6307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in /opt/conda/lib/python3.11/site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydicom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f1bcf7-c78d-43a8-917f-70ccd9ba45aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c9c22b-13d6-4cea-b6d4-082fe9e14932",
   "metadata": {},
   "source": [
    "./rsna_output/cvt_png/\n",
    "    {study_id}/\n",
    "        {series_id}/\n",
    "            1.png\n",
    "            2.png\n",
    "            ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48b13b9-37de-4a9d-84d2-15848882834a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Check for available device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60dc203a-f422-4373-8e14-bf1e244ddbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main DataFrame Columns: ['study_id', 'spinal_canal_stenosis_l1_l2', 'spinal_canal_stenosis_l2_l3', 'spinal_canal_stenosis_l3_l4', 'spinal_canal_stenosis_l4_l5', 'spinal_canal_stenosis_l5_s1', 'left_neural_foraminal_narrowing_l1_l2', 'left_neural_foraminal_narrowing_l2_l3', 'left_neural_foraminal_narrowing_l3_l4', 'left_neural_foraminal_narrowing_l4_l5', 'left_neural_foraminal_narrowing_l5_s1', 'right_neural_foraminal_narrowing_l1_l2', 'right_neural_foraminal_narrowing_l2_l3', 'right_neural_foraminal_narrowing_l3_l4', 'right_neural_foraminal_narrowing_l4_l5', 'right_neural_foraminal_narrowing_l5_s1', 'left_subarticular_stenosis_l1_l2', 'left_subarticular_stenosis_l2_l3', 'left_subarticular_stenosis_l3_l4', 'left_subarticular_stenosis_l4_l5', 'left_subarticular_stenosis_l5_s1', 'right_subarticular_stenosis_l1_l2', 'right_subarticular_stenosis_l2_l3', 'right_subarticular_stenosis_l3_l4', 'right_subarticular_stenosis_l4_l5', 'right_subarticular_stenosis_l5_s1']\n",
      "Coordinates DataFrame Columns: ['study_id', 'series_id', 'instance_number', 'condition', 'level', 'x', 'y', 'series_description', 'slice_number', 'original_height', 'original_width', 'x_scaled', 'y_scaled']\n",
      "Series Description DataFrame Columns: ['study_id', 'series_id', 'series_description']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1847/2734567135.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace(label2id, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "SERIES_DESCRIPTIONS = ['Sagittal T1', 'Sagittal T2_STIR', 'Axial T2']\n",
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis',\n",
    "    'left_neural_foraminal_narrowing',\n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n",
    "LEVELS = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n",
    "LABELS = [f'{condition}_{level}' for condition in CONDITIONS for level in LEVELS]\n",
    "\n",
    "# Set the root directory for your Kaggle files\n",
    "rd = './kaggle-files'\n",
    "\n",
    "# Load the main CSV file\n",
    "df = pd.read_csv(f'{rd}/train.csv')\n",
    "\n",
    "df = df.fillna(-100)  # Use -100 to indicate missing labels\n",
    "\n",
    "# Map the labels to integers for multi-class classification\n",
    "label2id = {'Normal/Mild': 0, 'Moderate': 1, 'Severe': 2}\n",
    "df.replace(label2id, inplace=True)\n",
    "\n",
    "\n",
    "# Load the coordinates data\n",
    "coordinates_df = pd.read_csv(f'{rd}/dfc_updated.csv')\n",
    "coordinates_df = coordinates_df.dropna(subset=['slice_number'])\n",
    "coordinates_df['slice_number'] = coordinates_df['slice_number'].astype(int)\n",
    "\n",
    "# Normalize series descriptions\n",
    "coordinates_df['series_description'] = coordinates_df['series_description'].str.replace('T2/STIR', 'T2_STIR')\n",
    "\n",
    "# Load the series descriptions\n",
    "series_description_df = pd.read_csv(f'{rd}/train_series_descriptions.csv')\n",
    "series_description_df['series_description'] = series_description_df['series_description'].str.replace('T2/STIR', 'T2_STIR')\n",
    "\n",
    "# Verify loaded data\n",
    "print(\"Main DataFrame Columns:\", df.columns.tolist())\n",
    "print(\"Coordinates DataFrame Columns:\", coordinates_df.columns.tolist())\n",
    "print(\"Series Description DataFrame Columns:\", series_description_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cfa503c-7b02-47bd-8712-bb297e62b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize3D(object):\n",
    "    def __init__(self, mean, std):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mean (list or tuple): Mean values for each channel.\n",
    "            std (list or tuple): Standard deviation values for each channel.\n",
    "        \"\"\"\n",
    "        self.mean = torch.tensor(mean).view(-1, 1, 1, 1)  # Shape: [C, 1, 1, 1]\n",
    "        self.std = torch.tensor(std).view(-1, 1, 1, 1)    # Shape: [C, 1, 1, 1]\n",
    "    \n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (torch.Tensor): Tensor image of size [C, D, H, W] to be normalized.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Normalized tensor.\n",
    "        \"\"\"\n",
    "        return (tensor - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e25e267-b310-4243-beeb-b969f3bcf6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ec8d87e-d8e6-4b42-acd5-68793397845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LumbarSpine3DDataset(Dataset):\n",
    "    def __init__(self, df, coordinates_df, series_description_df, root_dir, transform=None, target_slices=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (DataFrame): DataFrame containing labels.\n",
    "            coordinates_df (DataFrame): DataFrame containing coordinates.\n",
    "            series_description_df (DataFrame): DataFrame containing series descriptions.\n",
    "            root_dir (str): Root directory for MRI scans.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            target_slices (int): Number of slices to resample or pad to.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.coordinates_df = coordinates_df\n",
    "        self.series_description_df = series_description_df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.target_slices = target_slices\n",
    "        self.labels = LABELS\n",
    "\n",
    "        # Generate a list of study IDs\n",
    "        self.study_ids = self.df['study_id'].unique()\n",
    "        self.labels = LABELS\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.study_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        study_id = self.study_ids[idx]\n",
    "        study_data = self.df[self.df['study_id'] == study_id]\n",
    "        labels = study_data[self.labels].values.flatten()\n",
    "        \n",
    "        # Convert labels to torch.long without casting via .astype(int)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "        # Load scans for each series description\n",
    "        scans = []\n",
    "        for series in SERIES_DESCRIPTIONS:\n",
    "            # Get the series ID for the current study and series description\n",
    "            series_id = self.get_series_id(study_id, series)\n",
    "            if series_id is None:\n",
    "                # Handle missing series by adding zeroed slices\n",
    "                scans.append(torch.zeros((1, self.target_slices, 512, 512)))\n",
    "                continue\n",
    "\n",
    "            # Load the scan\n",
    "            scan = self.load_scan(study_id, series_id)\n",
    "            if scan is None:\n",
    "                scans.append(torch.zeros((1, self.target_slices, 512, 512)))\n",
    "                continue\n",
    "\n",
    "            # Resample or pad to target_slices\n",
    "            scan = self.resample_slices(scan, target_slices=self.target_slices)\n",
    "\n",
    "            # Convert to tensor and add channel dimension\n",
    "            scan = torch.from_numpy(scan).float()  # Shape: [slices, H, W]\n",
    "            scan = scan.unsqueeze(0)  # Shape: [1, slices, H, W]\n",
    "            scans.append(scan)\n",
    "\n",
    "        # Concatenate scans along the channel dimension\n",
    "        # Resulting shape: [channels, slices, H, W]\n",
    "        scan = torch.cat(scans, dim=0)\n",
    "\n",
    "        # Get coordinates\n",
    "        coords = self.get_coordinates(study_id)\n",
    "        coords = torch.tensor(coords).float()\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            scan = self.transform(scan)\n",
    "\n",
    "        sample = {'scan': scan, 'labels': labels, 'coords': coords}\n",
    "        return sample\n",
    "\n",
    "    def load_scan(self, study_id, series_id):\n",
    "        \"\"\"\n",
    "        Load all PNG slices for a given study_id and series_id.\n",
    "        Args:\n",
    "            study_id (str/int): The study identifier.\n",
    "            series_id (str/int): The series identifier.\n",
    "        Returns:\n",
    "            np.ndarray: 3D array of shape [slices, H, W] or None if not found.\n",
    "        \"\"\"\n",
    "        series_dir = os.path.join(self.root_dir, str(study_id), str(series_id))\n",
    "        if not os.path.exists(series_dir):\n",
    "            return None\n",
    "        slice_files = sorted(os.listdir(series_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "        slices = []\n",
    "        for slice_file in slice_files:\n",
    "            slice_path = os.path.join(series_dir, slice_file)\n",
    "            slice_data = self.load_slice(slice_path)\n",
    "            if slice_data is None:\n",
    "                continue\n",
    "            slices.append(slice_data)\n",
    "        if not slices:\n",
    "            return None\n",
    "        volume = np.stack(slices, axis=0)  # Shape: [slices, H, W]\n",
    "        return volume\n",
    "\n",
    "    def load_slice(self, slice_path):\n",
    "        \"\"\"\n",
    "        Load a single PNG slice.\n",
    "        Args:\n",
    "            slice_path (str): Path to the PNG file.\n",
    "        Returns:\n",
    "            np.ndarray: 2D array of the image or None if failed.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            img = Image.open(slice_path).convert('L')  # Convert to grayscale\n",
    "            img = img.resize((512, 512))  # Resize to 512x512 if necessary\n",
    "            img = np.array(img).astype(np.float32)\n",
    "            if np.isnan(img).any():\n",
    "                print(f\"NaN values found in slice {slice_path}. Replacing with zeros.\")\n",
    "                img = np.nan_to_num(img)\n",
    "            return img\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading slice {slice_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def resample_slices(self, volume, target_slices=10):\n",
    "        \"\"\"\n",
    "        Resample or pad the number of slices to target_slices.\n",
    "        Args:\n",
    "            volume (np.ndarray): 3D array of shape [slices, H, W].\n",
    "            target_slices (int): Desired number of slices.\n",
    "        Returns:\n",
    "            np.ndarray: Resampled 3D array.\n",
    "        \"\"\"\n",
    "        current_slices = volume.shape[0]\n",
    "        if current_slices == target_slices:\n",
    "            return volume\n",
    "        elif current_slices > target_slices:\n",
    "            indices = np.linspace(0, current_slices - 1, target_slices).astype(int)\n",
    "            return volume[indices]\n",
    "        else:\n",
    "            # Pad with zeros\n",
    "            pad_width = target_slices - current_slices\n",
    "            padding = ((0, pad_width), (0, 0), (0, 0))\n",
    "            return np.pad(volume, padding, mode='constant', constant_values=0)\n",
    "\n",
    "    def get_series_id(self, study_id, series_description):\n",
    "        \"\"\"\n",
    "        Get the series_id for a given study_id and series_description.\n",
    "        Args:\n",
    "            study_id (str/int): The study identifier.\n",
    "            series_description (str): The series description.\n",
    "        Returns:\n",
    "            str/int or None: The series_id or None if not found.\n",
    "        \"\"\"\n",
    "        series_info = self.series_description_df[\n",
    "            (self.series_description_df['study_id'] == study_id) &\n",
    "            (self.series_description_df['series_description'] == series_description)\n",
    "        ]\n",
    "        if series_info.empty:\n",
    "            return None\n",
    "        return series_info.iloc[0]['series_id']\n",
    "\n",
    "    def get_coordinates(self, study_id):\n",
    "        \"\"\"\n",
    "        Extract coordinates for all conditions and levels for the study.\n",
    "        Args:\n",
    "            study_id (str/int): The study identifier.\n",
    "        Returns:\n",
    "            list: List of [x_scaled, y_scaled] for each condition and level.\n",
    "        \"\"\"\n",
    "        study_coords = self.coordinates_df[self.coordinates_df['study_id'] == study_id]\n",
    "        coords = []\n",
    "        for condition in CONDITIONS:\n",
    "            condition_name = condition.replace('_', ' ').title()\n",
    "            for level in LEVELS:\n",
    "                level_name = level.upper().replace('_', '/')  # Convert 'l1_l2' to 'L1/L2'\n",
    "                coord_entry = study_coords[\n",
    "                    (study_coords['condition'] == condition_name) &\n",
    "                    (study_coords['level'] == level_name)\n",
    "                ]\n",
    "                if not coord_entry.empty:\n",
    "                    x = coord_entry.iloc[0]['x_scaled']\n",
    "                    y = coord_entry.iloc[0]['y_scaled']\n",
    "                    coords.extend([x, y])\n",
    "                else:\n",
    "                    # If no coordinate, fill with zeros\n",
    "                    coords.extend([0.0, 0.0])\n",
    "        return coords  # List of coordinates for all conditions and levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c56d16-1ad7-445c-82bc-0aa5bafbd1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class BasicBlock3D(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock3D, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv3d(planes, planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.se = SEBlock(planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out = self.se(out)  # Apply SE block\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet3D(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=512):\n",
    "        super(ResNet3D, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        # Updated to accept 3 channels instead of 1\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=7, stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=(1, 2, 2), padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(self.in_planes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_planes, planes, stride, downsample))\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x: [batch_size, 3, slices, H, W]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)  # [batch, 64, slices, H/4, W/4]\n",
    "        x = self.layer2(x)  # [batch, 128, slices/2, H/8, W/8]\n",
    "        x = self.layer3(x)  # [batch, 256, slices/4, H/16, W/16]\n",
    "        x = self.layer4(x)  # [batch, 512, slices/8, H/32, W/32]\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x  # [batch_size, num_classes]\n",
    "\n",
    "def resnet18_3d(num_classes=512):\n",
    "    \"\"\"Constructs a ResNet-18 3D model.\"\"\"\n",
    "    model = ResNet3D(BasicBlock3D, [2, 2, 2, 2], num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "class CoordAttention3DResNet(nn.Module):\n",
    "    def __init__(self, num_classes, coord_dim):\n",
    "        super(CoordAttention3DResNet, self).__init__()\n",
    "        self.resnet3d = ResNet3D(BasicBlock3D, [2, 2, 2, 2], num_classes=512)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        self.coord_attention = CoordAttentionModule(512, coord_dim)\n",
    "\n",
    "    def forward(self, x, coords=None):\n",
    "        x = self.resnet3d(x)  # [batch_size, 512]\n",
    "        if self.training and coords is not None:\n",
    "            x = self.coord_attention(x, coords)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class CoordAttentionModule(nn.Module):\n",
    "    def __init__(self, feature_dim, coord_dim):\n",
    "        super(CoordAttentionModule, self).__init__()\n",
    "        self.attention_fc = nn.Sequential(\n",
    "            nn.Linear(coord_dim, feature_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(feature_dim, feature_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, coords):\n",
    "        attention_weights = self.attention_fc(coords)  # [batch_size, feature_dim]\n",
    "        x = x * attention_weights  # Element-wise multiplication\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e4e064-123d-4a9f-9a92-37ff9bcfb4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset, num_classes, num_epochs=25, k_folds=5, batch_size=2):\n",
    "    \"\"\"\n",
    "    Train the model using K-Fold cross-validation.\n",
    "    Args:\n",
    "        dataset (Dataset): The dataset to train on.\n",
    "        num_classes (int): Number of classes per label.\n",
    "        num_epochs (int): Number of training epochs.\n",
    "        k_folds (int): Number of K-Folds.\n",
    "        batch_size (int): Batch size for training.\n",
    "    Returns:\n",
    "        dict: Validation loss for each fold.\n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    fold_performance = {}\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f'\\nFold {fold + 1}/{k_folds}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Sample elements randomly from a given list of indices\n",
    "        train_subsampler = Subset(dataset, train_idx)\n",
    "        val_subsampler = Subset(dataset, val_idx)\n",
    "\n",
    "        # Define data loaders\n",
    "        train_loader = DataLoader(train_subsampler, batch_size=batch_size, shuffle=True,\n",
    "                                  num_workers=4, pin_memory=True)\n",
    "        val_loader = DataLoader(val_subsampler, batch_size=batch_size, shuffle=False,\n",
    "                                num_workers=4, pin_memory=True)\n",
    "\n",
    "        # Initialize the model\n",
    "        coord_dim = len(CONDITIONS) * len(LEVELS) * 2  # 2 coordinates per condition per level\n",
    "        num_labels = len(LABELS)\n",
    "        model = CoordAttention3DResNet(num_classes=num_labels * num_classes, coord_dim=coord_dim)\n",
    "        model.to(device)\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                         patience=2, factor=0.5, verbose=True)\n",
    "\n",
    "        # Early stopping parameters\n",
    "        early_stopping_patience = 5\n",
    "        best_val_loss = np.inf\n",
    "        epochs_no_improve = 0\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloader = train_loader\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloader = val_loader\n",
    "\n",
    "                running_loss = 0.0\n",
    "\n",
    "                # Iterate over data\n",
    "                for batch in tqdm(dataloader, desc=f'{phase.capitalize()} Progress'):\n",
    "                    scans = batch['scan'].to(device)      # [batch_size, 3, 10, 512, 512]\n",
    "                    labels = batch['labels'].to(device)    # [batch_size, num_labels]\n",
    "                    coords = batch['coords'].to(device)    # [batch_size, coord_dim]\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Forward\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        if phase == 'train':\n",
    "                            outputs = model(scans, coords)  # [batch_size, num_labels * num_classes]\n",
    "                        else:\n",
    "                            outputs = model(scans)          # [batch_size, num_labels * num_classes]\n",
    "\n",
    "                        # Reshape outputs and labels for loss computation\n",
    "                        outputs = outputs.view(-1, num_classes)  # [batch_size * num_labels, num_classes]\n",
    "                        labels = labels.view(-1)                  # [batch_size * num_labels]\n",
    "\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # Backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # Statistics\n",
    "                    running_loss += loss.item() * scans.size(0)\n",
    "\n",
    "                epoch_loss = running_loss / len(dataloader.dataset)\n",
    "\n",
    "                print(f'{phase.capitalize()} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "                # Deep copy the model\n",
    "                if phase == 'val':\n",
    "                    scheduler.step(epoch_loss)\n",
    "                    if epoch_loss < best_val_loss:\n",
    "                        best_val_loss = epoch_loss\n",
    "                        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                        epochs_no_improve = 0\n",
    "                        print(f'Validation loss decreased to {best_val_loss:.4f}. Saving model...')\n",
    "                    else:\n",
    "                        epochs_no_improve += 1\n",
    "                        print(f'No improvement in validation loss for {epochs_no_improve} epochs.')\n",
    "\n",
    "            # Check early stopping condition\n",
    "            if epochs_no_improve >= early_stopping_patience:\n",
    "                print(f'\\nEarly stopping triggered after {early_stopping_patience} epochs without improvement.')\n",
    "                break\n",
    "\n",
    "        print(f'\\nBest Validation Loss for Fold {fold + 1}: {best_val_loss:.4f}')\n",
    "\n",
    "        # Load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "\n",
    "        # Save the best model for this fold\n",
    "        torch.save(model.state_dict(), f'model_fold_{fold + 1}.pth')\n",
    "        print(f'Saved best model for Fold {fold + 1}.')\n",
    "\n",
    "        # Record fold performance\n",
    "        fold_performance[fold + 1] = best_val_loss\n",
    "\n",
    "    return fold_performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "871475de-be6b-44bd-a8df-29aa257453d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_log_loss(outputs, targets, severity_weights, ignore_index=-100):\n",
    "    \"\"\"\n",
    "    Calculate the weighted log loss.\n",
    "    Args:\n",
    "        outputs (torch.Tensor): Logits from the model, shape [N, C].\n",
    "        targets (torch.Tensor): Ground truth labels, shape [N].\n",
    "        severity_weights (torch.Tensor): Weights for each class, shape [C].\n",
    "        ignore_index (int): Label to ignore.\n",
    "    Returns:\n",
    "        torch.Tensor: Weighted log loss.\n",
    "    \"\"\"\n",
    "    # Apply log_softmax to get log probabilities\n",
    "    log_probs = F.log_softmax(outputs, dim=1)  # [N, C]\n",
    "    \n",
    "    # Gather the log probabilities corresponding to the targets\n",
    "    targets = targets.view(-1, 1)\n",
    "    log_probs = log_probs.gather(1, targets).squeeze(1)  # [N]\n",
    "    \n",
    "    # Get the weights for each target\n",
    "    weights = severity_weights[targets.squeeze(1)]  # [N]\n",
    "    \n",
    "    # Compute loss, ignoring the ignore_index\n",
    "    loss = -log_probs * weights\n",
    "    loss = loss[targets.squeeze(1) != ignore_index]\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9e05574-5c59-476f-b017-96ce1f8b0e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "Scan shape: torch.Size([3, 10, 512, 512])\n",
      "Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "Coordinates: tensor([258.2655, 182.3717, 256.4572, 236.5714, 258.4243, 297.4546, 268.2336,\n",
      "        341.8619, 282.7328, 387.1717, 261.4276, 168.0283, 255.0954, 226.8269,\n",
      "        250.5045, 289.6601, 248.6726, 335.4562, 262.8008, 385.9431, 259.4264,\n",
      "        170.3403, 255.5105, 221.2467, 249.6367, 280.9637,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000, 286.6023, 257.9768, 289.5676, 254.0232, 281.6602,\n",
      "        252.0463, 276.7181, 251.0579, 287.5907, 258.9652, 232.4620, 253.7994,\n",
      "        233.4401, 251.3543, 228.5499, 249.8873, 235.8851, 252.8214, 233.4401,\n",
      "        258.2006])\n",
      "\n",
      "\n",
      "Sample 1:\n",
      "Scan shape: torch.Size([3, 10, 512, 512])\n",
      "Labels: tensor([0, 0, 1, 2, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1,\n",
      "        0])\n",
      "Coordinates: tensor([  0.0000,   0.0000,   0.0000,   0.0000, 310.7159, 257.5971,   0.0000,\n",
      "          0.0000, 345.3683, 351.6007, 320.9129, 132.0140,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000, 314.6411, 341.6307, 318.6398,\n",
      "        138.3648,   0.0000,   0.0000,   0.0000,   0.0000, 293.5619, 289.0083,\n",
      "        314.6801, 331.7141, 313.7561, 352.1115, 313.7561, 339.6237, 311.9721,\n",
      "        337.8397, 296.8083, 352.1115, 278.9686, 373.5192, 245.5747, 350.9864,\n",
      "        267.9698, 342.4917, 272.6033, 337.0860, 251.7526, 348.6697, 230.1297,\n",
      "        380.3318])\n",
      "\n",
      "\n",
      "Sample 2:\n",
      "Scan shape: torch.Size([3, 10, 512, 512])\n",
      "Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "Coordinates: tensor([284.7015, 149.9638, 275.4456, 208.4225, 266.8210, 264.5593, 265.3398,\n",
      "        319.3636, 280.1517, 366.2681, 280.4041, 139.6885, 274.6397, 196.5613,\n",
      "          0.0000,   0.0000, 258.5503, 311.6660, 265.9908, 363.2242,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "        264.3543, 358.6473, 283.6389, 277.5221, 280.9203, 267.5540, 280.0142,\n",
      "        258.4920, 272.7646, 257.5858, 275.4832, 271.1788, 233.7538, 281.0046,\n",
      "        230.9755, 266.3194, 232.9600, 259.9690, 229.3879, 260.3659, 227.0065,\n",
      "        273.4636])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define transformations using the custom Normalize3D\n",
    "transform = transforms.Compose([\n",
    "    Normalize3D(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Adjust mean and std as needed\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "root_dir = './rsna_output/cvt_png'  # Adjust this path to where your PNG images are stored\n",
    "dataset = LumbarSpine3DDataset(df, coordinates_df, series_description_df, root_dir,\n",
    "                               transform=transform, target_slices=10)\n",
    "\n",
    "# Verify a few samples to ensure data is loaded correctly\n",
    "for i in range(3):\n",
    "    sample = dataset[i]\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(f\"Scan shape: {sample['scan'].shape}\")  # Expected: [3, 10, 512, 512]\n",
    "    print(f\"Labels: {sample['labels']}\")\n",
    "    print(f\"Coordinates: {sample['coords']}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b5bd3-980f-4d1b-984a-a53584947374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/2\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Progress: 100%|██████████| 494/494 [05:58<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Progress: 100%|██████████| 494/494 [01:53<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6379\n",
      "Validation loss decreased to 0.6379. Saving model...\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Progress: 100%|██████████| 494/494 [05:58<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Progress: 100%|██████████| 494/494 [01:53<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6363\n",
      "Validation loss decreased to 0.6363. Saving model...\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Progress: 100%|██████████| 494/494 [05:59<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Progress: 100%|██████████| 494/494 [01:53<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6634\n",
      "No improvement in validation loss for 1 epochs.\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Progress: 100%|██████████| 494/494 [05:59<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Progress: 100%|██████████| 494/494 [01:53<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6705\n",
      "No improvement in validation loss for 2 epochs.\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Progress: 100%|██████████| 494/494 [01:53<00:00,  4.35it/s]s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6136\n",
      "Validation loss decreased to 0.6136. Saving model...\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Progress: 100%|██████████| 494/494 [05:59<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Progress: 100%|██████████| 494/494 [01:53<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6217\n",
      "No improvement in validation loss for 1 epochs.\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Progress: 100%|██████████| 494/494 [05:59<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Progress: 100%|██████████| 494/494 [01:53<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6488\n",
      "No improvement in validation loss for 2 epochs.\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Progress:  40%|████      | 199/494 [02:24<03:33,  1.38it/s]"
     ]
    }
   ],
   "source": [
    "# Number of classes per label (e.g., 3 for Normal/Mild, Moderate, Severe)\n",
    "k_folds = 2  # Number of folds you used during training\n",
    "num_classes = 3  # Number of classes per label\n",
    "num_epochs = 5  # Number of epochs you trained for\n",
    "\n",
    "\n",
    "# Train the model\n",
    "fold_performance = train_model(dataset, num_classes=num_classes, num_epochs=num_epochs, k_folds=k_folds, batch_size=2)\n",
    "\n",
    "# Print fold performance\n",
    "for fold, loss in fold_performance.items():\n",
    "    print(f'Fold {fold}, Best Validation Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b5cb39-5c35-40a3-b528-bfea865c51ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e771dc5-0991-48f9-8e1e-2c118844ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, model_class, model_paths, device):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.models = nn.ModuleList()\n",
    "        for path in model_paths:\n",
    "            # Initialize the model with necessary parameters\n",
    "            model = model_class()\n",
    "            # Load the saved state dict\n",
    "            model.load_state_dict(torch.load(path, map_location=device))\n",
    "            model.to(device)\n",
    "            model.eval()  # Set model to evaluation mode\n",
    "            self.models.append(model)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs_list = []\n",
    "        for model in self.models:\n",
    "            outputs = model(x)\n",
    "            outputs_list.append(outputs)\n",
    "        # Stack outputs and take mean over the ensemble dimension\n",
    "        outputs = torch.stack(outputs_list, dim=0)\n",
    "        avg_outputs = torch.mean(outputs, dim=0)\n",
    "        return avg_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d71b7-b6e9-4fc8-a1c5-7b1d2392d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have defined the necessary imports and variables earlier\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Paths to your saved models from each fold\n",
    "model_paths = [f'model_fold_{i+1}.pth' for i in range(k_folds)]\n",
    "\n",
    "# Define the model class with necessary parameters\n",
    "coord_dim = len(CONDITIONS) * len(LEVELS) * 2  # As defined in your dataset\n",
    "num_labels = len(LABELS)\n",
    "\n",
    "# Since your model requires parameters, use a lambda function to pass them\n",
    "ensemble_model = EnsembleModel(\n",
    "    model_class=lambda: CoordAttention3DResNet(num_classes=num_labels * num_classes, coord_dim=coord_dim),\n",
    "    model_paths=model_paths,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "ensemble_model.to(device)\n",
    "ensemble_model.eval()\n",
    "\n",
    "# Optionally save the ensemble model's state_dict\n",
    "torch.save(ensemble_model.state_dict(), f'ensemble_3d_resnet_model_F{k_folds}_E{num_epochs}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04c730-423d-41e7-9f34-ebff8063a1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
