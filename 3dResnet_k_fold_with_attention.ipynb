{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7df27ede-34b3-4092-91c9-6a96260c6307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydicom\n",
      "  Using cached pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Using cached pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
      "Installing collected packages: pydicom\n",
      "Successfully installed pydicom-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydicom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b1f1bcf7-c78d-43a8-917f-70ccd9ba45aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c9c22b-13d6-4cea-b6d4-082fe9e14932",
   "metadata": {},
   "source": [
    "./rsna_output/cvt_png/\n",
    "    {study_id}/\n",
    "        {series_id}/\n",
    "            1.png\n",
    "            2.png\n",
    "            ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f48b13b9-37de-4a9d-84d2-15848882834a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Set random seeds for reproducibility\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     19\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/random.py:40\u001b[0m, in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmps\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/random.py:113\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    110\u001b[0m         default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[1;32m    111\u001b[0m         default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m--> 113\u001b[0m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:183\u001b[0m, in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lazy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 183\u001b[0m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/random.py:111\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[1;32m    110\u001b[0m     default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[0;32m--> 111\u001b[0m     \u001b[43mdefault_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Check for available device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "60dc203a-f422-4373-8e14-bf1e244ddbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main DataFrame Columns: ['study_id', 'spinal_canal_stenosis_l1_l2', 'spinal_canal_stenosis_l2_l3', 'spinal_canal_stenosis_l3_l4', 'spinal_canal_stenosis_l4_l5', 'spinal_canal_stenosis_l5_s1', 'left_neural_foraminal_narrowing_l1_l2', 'left_neural_foraminal_narrowing_l2_l3', 'left_neural_foraminal_narrowing_l3_l4', 'left_neural_foraminal_narrowing_l4_l5', 'left_neural_foraminal_narrowing_l5_s1', 'right_neural_foraminal_narrowing_l1_l2', 'right_neural_foraminal_narrowing_l2_l3', 'right_neural_foraminal_narrowing_l3_l4', 'right_neural_foraminal_narrowing_l4_l5', 'right_neural_foraminal_narrowing_l5_s1', 'left_subarticular_stenosis_l1_l2', 'left_subarticular_stenosis_l2_l3', 'left_subarticular_stenosis_l3_l4', 'left_subarticular_stenosis_l4_l5', 'left_subarticular_stenosis_l5_s1', 'right_subarticular_stenosis_l1_l2', 'right_subarticular_stenosis_l2_l3', 'right_subarticular_stenosis_l3_l4', 'right_subarticular_stenosis_l4_l5', 'right_subarticular_stenosis_l5_s1']\n",
      "Coordinates DataFrame Columns: ['study_id', 'series_id', 'instance_number', 'condition', 'level', 'x', 'y', 'series_description', 'slice_number', 'original_height', 'original_width', 'x_scaled', 'y_scaled']\n",
      "Series Description DataFrame Columns: ['study_id', 'series_id', 'series_description']\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "SERIES_DESCRIPTIONS = ['Sagittal T1', 'Sagittal T2_STIR', 'Axial T2']\n",
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis',\n",
    "    'left_neural_foraminal_narrowing',\n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n",
    "LEVELS = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n",
    "LABELS = [f'{condition}_{level}' for condition in CONDITIONS for level in LEVELS]\n",
    "\n",
    "# Set the root directory for your Kaggle files\n",
    "rd = './kaggle-files'\n",
    "\n",
    "# Load the main CSV file\n",
    "df = pd.read_csv(f'{rd}/train.csv')\n",
    "\n",
    "df = df.fillna(-100)  # Use -100 to indicate missing labels\n",
    "\n",
    "# Map the labels to integers for multi-class classification\n",
    "label2id = {'Normal/Mild': 0, 'Moderate': 1, 'Severe': 2}\n",
    "df.replace(label2id, inplace=True)\n",
    "\n",
    "\n",
    "# Load the coordinates data\n",
    "coordinates_df = pd.read_csv(f'{rd}/dfc_updated.csv')\n",
    "coordinates_df = coordinates_df.dropna(subset=['slice_number'])\n",
    "coordinates_df['slice_number'] = coordinates_df['slice_number'].astype(int)\n",
    "\n",
    "# Normalize series descriptions\n",
    "coordinates_df['series_description'] = coordinates_df['series_description'].str.replace('T2/STIR', 'T2_STIR')\n",
    "\n",
    "# Load the series descriptions\n",
    "series_description_df = pd.read_csv(f'{rd}/train_series_descriptions.csv')\n",
    "series_description_df['series_description'] = series_description_df['series_description'].str.replace('T2/STIR', 'T2_STIR')\n",
    "\n",
    "# Verify loaded data\n",
    "print(\"Main DataFrame Columns:\", df.columns.tolist())\n",
    "print(\"Coordinates DataFrame Columns:\", coordinates_df.columns.tolist())\n",
    "print(\"Series Description DataFrame Columns:\", series_description_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7cfa503c-7b02-47bd-8712-bb297e62b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize3D(object):\n",
    "    def __init__(self, mean, std):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mean (list or tuple): Mean values for each channel.\n",
    "            std (list or tuple): Standard deviation values for each channel.\n",
    "        \"\"\"\n",
    "        self.mean = torch.tensor(mean).view(-1, 1, 1, 1)  # Shape: [C, 1, 1, 1]\n",
    "        self.std = torch.tensor(std).view(-1, 1, 1, 1)    # Shape: [C, 1, 1, 1]\n",
    "    \n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (torch.Tensor): Tensor image of size [C, D, H, W] to be normalized.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Normalized tensor.\n",
    "        \"\"\"\n",
    "        return (tensor - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e25e267-b310-4243-beeb-b969f3bcf6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6ec8d87e-d8e6-4b42-acd5-68793397845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LumbarSpine3DDataset(Dataset):\n",
    "    def __init__(self, df, coordinates_df, series_description_df, root_dir, transform=None, target_slices=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (DataFrame): DataFrame containing labels.\n",
    "            coordinates_df (DataFrame): DataFrame containing coordinates.\n",
    "            series_description_df (DataFrame): DataFrame containing series descriptions.\n",
    "            root_dir (str): Root directory for MRI scans.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            target_slices (int): Number of slices to resample or pad to.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.coordinates_df = coordinates_df\n",
    "        self.series_description_df = series_description_df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.target_slices = target_slices\n",
    "        self.labels = LABELS\n",
    "\n",
    "        # Generate a list of study IDs\n",
    "        self.study_ids = self.df['study_id'].unique()\n",
    "        self.labels = LABELS\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.study_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        study_id = self.study_ids[idx]\n",
    "        study_data = self.df[self.df['study_id'] == study_id]\n",
    "        labels = study_data[self.labels].values.flatten()\n",
    "        \n",
    "        # Convert labels to torch.long without casting via .astype(int)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "        # Load scans for each series description\n",
    "        scans = []\n",
    "        for series in SERIES_DESCRIPTIONS:\n",
    "            # Get the series ID for the current study and series description\n",
    "            series_id = self.get_series_id(study_id, series)\n",
    "            if series_id is None:\n",
    "                # Handle missing series by adding zeroed slices\n",
    "                scans.append(torch.zeros((1, self.target_slices, 512, 512)))\n",
    "                continue\n",
    "\n",
    "            # Load the scan\n",
    "            scan = self.load_scan(study_id, series_id)\n",
    "            if scan is None:\n",
    "                scans.append(torch.zeros((1, self.target_slices, 512, 512)))\n",
    "                continue\n",
    "\n",
    "            # Resample or pad to target_slices\n",
    "            scan = self.resample_slices(scan, target_slices=self.target_slices)\n",
    "\n",
    "            # Convert to tensor and add channel dimension\n",
    "            scan = torch.from_numpy(scan).float()  # Shape: [slices, H, W]\n",
    "            scan = scan.unsqueeze(0)  # Shape: [1, slices, H, W]\n",
    "            scans.append(scan)\n",
    "\n",
    "        # Concatenate scans along the channel dimension\n",
    "        # Resulting shape: [channels, slices, H, W]\n",
    "        scan = torch.cat(scans, dim=0)\n",
    "\n",
    "        # Get coordinates\n",
    "        coords = self.get_coordinates(study_id)\n",
    "        coords = torch.tensor(coords).float()\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            scan = self.transform(scan)\n",
    "\n",
    "        sample = {'scan': scan, 'labels': labels, 'coords': coords}\n",
    "        return sample\n",
    "\n",
    "    def load_scan(self, study_id, series_id):\n",
    "        \"\"\"\n",
    "        Load all PNG slices for a given study_id and series_id.\n",
    "        Args:\n",
    "            study_id (str/int): The study identifier.\n",
    "            series_id (str/int): The series identifier.\n",
    "        Returns:\n",
    "            np.ndarray: 3D array of shape [slices, H, W] or None if not found.\n",
    "        \"\"\"\n",
    "        series_dir = os.path.join(self.root_dir, str(study_id), str(series_id))\n",
    "        if not os.path.exists(series_dir):\n",
    "            return None\n",
    "        slice_files = sorted(os.listdir(series_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "        slices = []\n",
    "        for slice_file in slice_files:\n",
    "            slice_path = os.path.join(series_dir, slice_file)\n",
    "            slice_data = self.load_slice(slice_path)\n",
    "            if slice_data is None:\n",
    "                continue\n",
    "            slices.append(slice_data)\n",
    "        if not slices:\n",
    "            return None\n",
    "        volume = np.stack(slices, axis=0)  # Shape: [slices, H, W]\n",
    "        return volume\n",
    "\n",
    "    def load_slice(self, slice_path):\n",
    "        \"\"\"\n",
    "        Load a single PNG slice.\n",
    "        Args:\n",
    "            slice_path (str): Path to the PNG file.\n",
    "        Returns:\n",
    "            np.ndarray: 2D array of the image or None if failed.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            img = Image.open(slice_path).convert('L')  # Convert to grayscale\n",
    "            img = img.resize((512, 512))  # Resize to 512x512 if necessary\n",
    "            img = np.array(img).astype(np.float32)\n",
    "            if np.isnan(img).any():\n",
    "                print(f\"NaN values found in slice {slice_path}. Replacing with zeros.\")\n",
    "                img = np.nan_to_num(img)\n",
    "            return img\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading slice {slice_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def resample_slices(self, volume, target_slices=10):\n",
    "        \"\"\"\n",
    "        Resample or pad the number of slices to target_slices.\n",
    "        Args:\n",
    "            volume (np.ndarray): 3D array of shape [slices, H, W].\n",
    "            target_slices (int): Desired number of slices.\n",
    "        Returns:\n",
    "            np.ndarray: Resampled 3D array.\n",
    "        \"\"\"\n",
    "        current_slices = volume.shape[0]\n",
    "        if current_slices == target_slices:\n",
    "            return volume\n",
    "        elif current_slices > target_slices:\n",
    "            indices = np.linspace(0, current_slices - 1, target_slices).astype(int)\n",
    "            return volume[indices]\n",
    "        else:\n",
    "            # Pad with zeros\n",
    "            pad_width = target_slices - current_slices\n",
    "            padding = ((0, pad_width), (0, 0), (0, 0))\n",
    "            return np.pad(volume, padding, mode='constant', constant_values=0)\n",
    "\n",
    "    def get_series_id(self, study_id, series_description):\n",
    "        \"\"\"\n",
    "        Get the series_id for a given study_id and series_description.\n",
    "        Args:\n",
    "            study_id (str/int): The study identifier.\n",
    "            series_description (str): The series description.\n",
    "        Returns:\n",
    "            str/int or None: The series_id or None if not found.\n",
    "        \"\"\"\n",
    "        series_info = self.series_description_df[\n",
    "            (self.series_description_df['study_id'] == study_id) &\n",
    "            (self.series_description_df['series_description'] == series_description)\n",
    "        ]\n",
    "        if series_info.empty:\n",
    "            return None\n",
    "        return series_info.iloc[0]['series_id']\n",
    "\n",
    "    def get_coordinates(self, study_id):\n",
    "        \"\"\"\n",
    "        Extract coordinates for all conditions and levels for the study.\n",
    "        Args:\n",
    "            study_id (str/int): The study identifier.\n",
    "        Returns:\n",
    "            list: List of [x_scaled, y_scaled] for each condition and level.\n",
    "        \"\"\"\n",
    "        study_coords = self.coordinates_df[self.coordinates_df['study_id'] == study_id]\n",
    "        coords = []\n",
    "        for condition in CONDITIONS:\n",
    "            condition_name = condition.replace('_', ' ').title()\n",
    "            for level in LEVELS:\n",
    "                level_name = level.upper().replace('_', '/')  # Convert 'l1_l2' to 'L1/L2'\n",
    "                coord_entry = study_coords[\n",
    "                    (study_coords['condition'] == condition_name) &\n",
    "                    (study_coords['level'] == level_name)\n",
    "                ]\n",
    "                if not coord_entry.empty:\n",
    "                    x = coord_entry.iloc[0]['x_scaled']\n",
    "                    y = coord_entry.iloc[0]['y_scaled']\n",
    "                    coords.extend([x, y])\n",
    "                else:\n",
    "                    # If no coordinate, fill with zeros\n",
    "                    coords.extend([0.0, 0.0])\n",
    "        return coords  # List of coordinates for all conditions and levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f1c56d16-1ad7-445c-82bc-0aa5bafbd1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class BasicBlock3D(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock3D, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv3d(planes, planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.se = SEBlock(planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out = self.se(out)  # Apply SE block\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet3D(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=512):\n",
    "        super(ResNet3D, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        # Updated to accept 3 channels instead of 1\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=7, stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=(1, 2, 2), padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(self.in_planes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_planes, planes, stride, downsample))\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x: [batch_size, 3, slices, H, W]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)  # [batch, 64, slices, H/4, W/4]\n",
    "        x = self.layer2(x)  # [batch, 128, slices/2, H/8, W/8]\n",
    "        x = self.layer3(x)  # [batch, 256, slices/4, H/16, W/16]\n",
    "        x = self.layer4(x)  # [batch, 512, slices/8, H/32, W/32]\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x  # [batch_size, num_classes]\n",
    "\n",
    "def resnet18_3d(num_classes=512):\n",
    "    \"\"\"Constructs a ResNet-18 3D model.\"\"\"\n",
    "    model = ResNet3D(BasicBlock3D, [2, 2, 2, 2], num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "class CoordAttention3DResNet(nn.Module):\n",
    "    def __init__(self, num_classes, coord_dim):\n",
    "        super(CoordAttention3DResNet, self).__init__()\n",
    "        self.resnet3d = resnet18_3d()\n",
    "        self.fc = nn.Linear(512 + coord_dim, num_classes)  # 512 from ResNet, coord_dim coordinates\n",
    "\n",
    "    def forward(self, x, coords=None):\n",
    "        x = self.resnet3d(x)  # [batch_size, 512]\n",
    "        if self.training and coords is not None:\n",
    "            x = torch.cat((x, coords), dim=1)  # [batch_size, 512 + coord_dim]\n",
    "        x = self.fc(x)  # [batch_size, num_classes]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "40e4e064-123d-4a9f-9a92-37ff9bcfb4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset, num_classes, num_epochs=25, k_folds=5, batch_size=2):\n",
    "    \"\"\"\n",
    "    Train the model using K-Fold cross-validation.\n",
    "    Args:\n",
    "        dataset (Dataset): The dataset to train on.\n",
    "        num_classes (int): Number of classes per label.\n",
    "        num_epochs (int): Number of training epochs.\n",
    "        k_folds (int): Number of K-Folds.\n",
    "        batch_size (int): Batch size for training.\n",
    "    Returns:\n",
    "        dict: Validation loss for each fold.\n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    fold_performance = {}\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f'\\nFold {fold + 1}/{k_folds}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Sample elements randomly from a given list of indices\n",
    "        train_subsampler = Subset(dataset, train_idx)\n",
    "        val_subsampler = Subset(dataset, val_idx)\n",
    "\n",
    "        # Define data loaders\n",
    "        train_loader = DataLoader(train_subsampler, batch_size=batch_size, shuffle=True,\n",
    "                                  num_workers=4, pin_memory=True)\n",
    "        val_loader = DataLoader(val_subsampler, batch_size=batch_size, shuffle=False,\n",
    "                                num_workers=4, pin_memory=True)\n",
    "\n",
    "        # Initialize the model\n",
    "        coord_dim = len(CONDITIONS) * len(LEVELS) * 2  # 2 coordinates per condition per level\n",
    "        num_labels = len(LABELS)\n",
    "        model = CoordAttention3DResNet(num_classes=num_labels * num_classes, coord_dim=coord_dim)\n",
    "        model.to(device)\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                         patience=2, factor=0.5, verbose=True)\n",
    "\n",
    "        # Early stopping parameters\n",
    "        early_stopping_patience = 5\n",
    "        best_val_loss = np.inf\n",
    "        epochs_no_improve = 0\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                    dataloader = train_loader\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "                    dataloader = val_loader\n",
    "\n",
    "                running_loss = 0.0\n",
    "\n",
    "                # Iterate over data\n",
    "                for batch in tqdm(dataloader, desc=f'{phase.capitalize()} Progress'):\n",
    "                    scans = batch['scan'].to(device)      # [batch_size, 3, 10, 512, 512]\n",
    "                    labels = batch['labels'].to(device)    # [batch_size, num_labels]\n",
    "                    coords = batch['coords'].to(device)    # [batch_size, coord_dim]\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Forward\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        if phase == 'train':\n",
    "                            outputs = model(scans, coords)  # [batch_size, num_labels * num_classes]\n",
    "                        else:\n",
    "                            outputs = model(scans)          # [batch_size, num_labels * num_classes]\n",
    "\n",
    "                        # Reshape outputs and labels for loss computation\n",
    "                        outputs = outputs.view(-1, num_classes)  # [batch_size * num_labels, num_classes]\n",
    "                        labels = labels.view(-1)                  # [batch_size * num_labels]\n",
    "\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # Backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # Statistics\n",
    "                    running_loss += loss.item() * scans.size(0)\n",
    "\n",
    "                epoch_loss = running_loss / len(dataloader.dataset)\n",
    "\n",
    "                print(f'{phase.capitalize()} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "                # Deep copy the model\n",
    "                if phase == 'val':\n",
    "                    scheduler.step(epoch_loss)\n",
    "                    if epoch_loss < best_val_loss:\n",
    "                        best_val_loss = epoch_loss\n",
    "                        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                        epochs_no_improve = 0\n",
    "                        print(f'Validation loss decreased to {best_val_loss:.4f}. Saving model...')\n",
    "                    else:\n",
    "                        epochs_no_improve += 1\n",
    "                        print(f'No improvement in validation loss for {epochs_no_improve} epochs.')\n",
    "\n",
    "            # Check early stopping condition\n",
    "            if epochs_no_improve >= early_stopping_patience:\n",
    "                print(f'\\nEarly stopping triggered after {early_stopping_patience} epochs without improvement.')\n",
    "                break\n",
    "\n",
    "        print(f'\\nBest Validation Loss for Fold {fold + 1}: {best_val_loss:.4f}')\n",
    "\n",
    "        # Load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "\n",
    "        # Save the best model for this fold\n",
    "        torch.save(model.state_dict(), f'model_fold_{fold + 1}.pth')\n",
    "        print(f'Saved best model for Fold {fold + 1}.')\n",
    "\n",
    "        # Record fold performance\n",
    "        fold_performance[fold + 1] = best_val_loss\n",
    "\n",
    "    return fold_performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "871475de-be6b-44bd-a8df-29aa257453d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_log_loss(outputs, targets, severity_weights, ignore_index=-100):\n",
    "    \"\"\"\n",
    "    Calculate the weighted log loss.\n",
    "    Args:\n",
    "        outputs (torch.Tensor): Logits from the model, shape [N, C].\n",
    "        targets (torch.Tensor): Ground truth labels, shape [N].\n",
    "        severity_weights (torch.Tensor): Weights for each class, shape [C].\n",
    "        ignore_index (int): Label to ignore.\n",
    "    Returns:\n",
    "        torch.Tensor: Weighted log loss.\n",
    "    \"\"\"\n",
    "    # Apply log_softmax to get log probabilities\n",
    "    log_probs = F.log_softmax(outputs, dim=1)  # [N, C]\n",
    "    \n",
    "    # Gather the log probabilities corresponding to the targets\n",
    "    targets = targets.view(-1, 1)\n",
    "    log_probs = log_probs.gather(1, targets).squeeze(1)  # [N]\n",
    "    \n",
    "    # Get the weights for each target\n",
    "    weights = severity_weights[targets.squeeze(1)]  # [N]\n",
    "    \n",
    "    # Compute loss, ignoring the ignore_index\n",
    "    loss = -log_probs * weights\n",
    "    loss = loss[targets.squeeze(1) != ignore_index]\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f9e05574-5c59-476f-b017-96ce1f8b0e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "Scan shape: torch.Size([3, 10, 512, 512])\n",
      "Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "Coordinates: tensor([258.2655, 182.3717, 256.4572, 236.5714, 258.4243, 297.4546, 268.2336,\n",
      "        341.8619, 282.7328, 387.1717, 261.4276, 168.0283, 255.0954, 226.8269,\n",
      "        250.5045, 289.6601, 248.6726, 335.4562, 262.8008, 385.9431, 259.4264,\n",
      "        170.3403, 255.5105, 221.2467, 249.6367, 280.9637,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000, 286.6023, 257.9768, 289.5676, 254.0232, 281.6602,\n",
      "        252.0463, 276.7181, 251.0579, 287.5907, 258.9652, 232.4620, 253.7994,\n",
      "        233.4401, 251.3543, 228.5499, 249.8873, 235.8851, 252.8214, 233.4401,\n",
      "        258.2006])\n",
      "\n",
      "\n",
      "Sample 1:\n",
      "Scan shape: torch.Size([3, 10, 512, 512])\n",
      "Labels: tensor([0, 0, 1, 2, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1,\n",
      "        0])\n",
      "Coordinates: tensor([  0.0000,   0.0000,   0.0000,   0.0000, 310.7159, 257.5971,   0.0000,\n",
      "          0.0000, 345.3683, 351.6007, 320.9129, 132.0140,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000, 314.6411, 341.6307, 318.6398,\n",
      "        138.3648,   0.0000,   0.0000,   0.0000,   0.0000, 293.5619, 289.0083,\n",
      "        314.6801, 331.7141, 313.7561, 352.1115, 313.7561, 339.6237, 311.9721,\n",
      "        337.8397, 296.8083, 352.1115, 278.9686, 373.5192, 245.5747, 350.9864,\n",
      "        267.9698, 342.4917, 272.6033, 337.0860, 251.7526, 348.6697, 230.1297,\n",
      "        380.3318])\n",
      "\n",
      "\n",
      "Sample 2:\n",
      "Scan shape: torch.Size([3, 10, 512, 512])\n",
      "Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "Coordinates: tensor([284.7015, 149.9638, 275.4456, 208.4225, 266.8210, 264.5593, 265.3398,\n",
      "        319.3636, 280.1517, 366.2681, 280.4041, 139.6885, 274.6397, 196.5613,\n",
      "          0.0000,   0.0000, 258.5503, 311.6660, 265.9908, 363.2242,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "        264.3543, 358.6473, 283.6389, 277.5221, 280.9203, 267.5540, 280.0142,\n",
      "        258.4920, 272.7646, 257.5858, 275.4832, 271.1788, 233.7538, 281.0046,\n",
      "        230.9755, 266.3194, 232.9600, 259.9690, 229.3879, 260.3659, 227.0065,\n",
      "        273.4636])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define transformations using the custom Normalize3D\n",
    "transform = transforms.Compose([\n",
    "    Normalize3D(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Adjust mean and std as needed\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "root_dir = './rsna_output/cvt_png'  # Adjust this path to where your PNG images are stored\n",
    "dataset = LumbarSpine3DDataset(df, coordinates_df, series_description_df, root_dir,\n",
    "                               transform=transform, target_slices=10)\n",
    "\n",
    "# Verify a few samples to ensure data is loaded correctly\n",
    "for i in range(3):\n",
    "    sample = dataset[i]\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(f\"Scan shape: {sample['scan'].shape}\")  # Expected: [3, 10, 512, 512]\n",
    "    print(f\"Labels: {sample['labels']}\")\n",
    "    print(f\"Coordinates: {sample['coords']}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "976b5bd3-980f-4d1b-984a-a53584947374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "--------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m fold_performance \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Print fold performance\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, loss \u001b[38;5;129;01min\u001b[39;00m fold_performance\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[95], line 34\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(dataset, num_classes, num_epochs, k_folds, batch_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m num_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(LABELS)\n\u001b[1;32m     33\u001b[0m model \u001b[38;5;241m=\u001b[39m CoordAttention3DResNet(num_classes\u001b[38;5;241m=\u001b[39mnum_labels \u001b[38;5;241m*\u001b[39m num_classes, coord_dim\u001b[38;5;241m=\u001b[39mcoord_dim)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Define loss function and optimizer\u001b[39;00m\n\u001b[1;32m     37\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Number of classes per label (e.g., 3 for Normal/Mild, Moderate, Severe)\n",
    "num_classes = 3\n",
    "\n",
    "# Train the model\n",
    "fold_performance = train_model(dataset, num_classes=num_classes, num_epochs=30, k_folds=5, batch_size=2)\n",
    "\n",
    "# Print fold performance\n",
    "for fold, loss in fold_performance.items():\n",
    "    print(f'Fold {fold}, Best Validation Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b5cb39-5c35-40a3-b528-bfea865c51ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e771dc5-0991-48f9-8e1e-2c118844ec02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af60f057-e803-467b-8599-a00f37874444",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2798228678.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    2. Dataset Class\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "2. Dataset Class\n",
    "We will create a custom dataset class that handles variable slices and incorporates coordinate features during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b9204-2c83-41b7-b665-067eb76a94dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f982dc32-1993-4563-8df6-245438d4a7e1",
   "metadata": {},
   "source": [
    "## 1. loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477a696-1878-40b9-9ee0-14079a01aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1, 1)\n",
    "        return x * y.expand_as(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
